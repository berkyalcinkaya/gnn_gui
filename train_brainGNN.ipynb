{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "635522a8-dc38-4bd4-af65-1fa950f9671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 2280, num validation examples: 585, total: 2865\n",
      "torch.float32 torch.float32 torch.int64 torch.float32 torch.int64\n",
      "Data(x=[268, 268], edge_index=[2, 64374], edge_attr=[64374, 1], y=[1], pos=[268, 268])\n"
     ]
    }
   ],
   "source": [
    "# X_paths = [f\"data/intermediate/siteE_Total_pearson_Aug_{i}.npy\" for i in [10,5,1]]\n",
    "# Y_path = \"data/intermediate/labels_for_aug.npy\"\n",
    "# X = np.load(X_paths[0])\n",
    "# Y = np.load(Y_path)\n",
    "# X.shape, Y.shape\n",
    "# data, train_loader, val_loader = get_data_grouped(X,Y)\n",
    "# print(data[0].x.dtype, data[0].pos.dtype, data[0].edge_index.dtype, data[0].edge_attr.dtype, data[0].y.dtype)\n",
    "# print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025045ea-59dc-4847-a390-30d2d74a7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/isilon/datalake/lcbn_research/final/NCANDA/berk/gnn/src/net/imports/gdc.py:13: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  return numba.jit(cache=True)(func)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.int64 torch.float32 torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# from src.net.imports.ABIDEDataset import ABIDEDataset\n",
    "# from torch_geometric.data import DataLoader\n",
    "# path = 'BrainGNN_Pytorch/data/ABIDE_pcp/cpac/filt_noglobal'\n",
    "# name = 'ABIDE'\n",
    "# dataset = ABIDEDataset(path,name)\n",
    "# dataset.data.y = dataset.data.y.squeeze()\n",
    "# dataset.data.x[dataset.data.x == float('inf')] = 0\n",
    "# print(dataset[0].x.dtype, dataset[0].pos.dtype, dataset[0].edge_index.dtype, dataset[0].edge_attr.dtype, dataset[0].y.dtype)\n",
    "# train_loader = DataLoader(dataset,batch_size=2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085beacb-3c5a-465e-824a-df23031aee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from src.data import get_data_grouped, get_data\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from src.net.braingnn import Network\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "EPS = 1e-10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4875e1-5b36-46ed-912a-33acdc64c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 3200, num validation examples: 800, total: 4000\n",
      "torch.float32 torch.float32 torch.int64 torch.float32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "X_path = \"data/intermediate/simulated.npy\"\n",
    "Y_path = \"data/intermediate/simulated_labels.npy\"\n",
    "X = np.load(X_path)\n",
    "Y = np.load(Y_path)\n",
    "X.shape, Y.shape\n",
    "data, train_loader, val_loader = get_data(X,Y)\n",
    "print(data[0].x.dtype, data[0].pos.dtype, data[0].edge_index.dtype, data[0].edge_attr.dtype, data[0].y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cca657-f3f3-48f8-9d8f-df8cbe97a958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for d in val_loader:\n",
    "    print(d.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7147138c-2e55-4c76-88b1-d0f3d5d4b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "num_epoch = 50\n",
    "batchSize = 32\n",
    "fold = 0\n",
    "lr = 0.01\n",
    "stepsize = 20\n",
    "gamma = 0.5\n",
    "weightdecay = 5e-3\n",
    "lamb0 = 1\n",
    "lamb1 = 0\n",
    "lamb2 = 0\n",
    "lamb3 = 0.1\n",
    "lamb4 = 0.1\n",
    "lamb5 = 0.1\n",
    "layer = 2\n",
    "ratio = 0.5\n",
    "indim = 30 # Change this\n",
    "nroi = 30\n",
    "nclass = 2\n",
    "load_model = True\n",
    "save_model = True\n",
    "opt_method = 'Adam'\n",
    "save_path = 'models/brainGNN_sim'\n",
    "writer = SummaryWriter(os.path.join('./log',str(fold)))\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff241b2-9943-4375-8f46-fedc55b7a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (n1): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=960, bias=True)\n",
      "  )\n",
      "  (conv1): MyNNConv(30, 32)\n",
      "  (pool1): TopKPooling(32, ratio=0.5, multiplier=1)\n",
      "  (n2): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=1024, bias=True)\n",
      "  )\n",
      "  (conv2): MyNNConv(32, 32)\n",
      "  (pool2): TopKPooling(32, ratio=0.5, multiplier=1)\n",
      "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "############### Define Graph Deep Learning Network ##########################\n",
    "model = Network(indim,ratio,nclass, R = nroi, k = 3).to(device)\n",
    "print(model)\n",
    "\n",
    "if opt_method == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= lr, weight_decay=weightdecay)\n",
    "elif opt_method == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr =lr, momentum = 0.9, weight_decay=weightdecay, nesterov = True)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=stepsize, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4373d47c-2c3c-4f7c-8e41-548ac7a263a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Define Other Loss Functions ########################################\n",
    "def topk_loss(s,ratio):\n",
    "    if ratio > 0.5:\n",
    "        ratio = 1-ratio\n",
    "    s = s.sort(dim=1).values\n",
    "    res =  -torch.log(s[:,-int(s.size(1)*ratio):]+EPS).mean() -torch.log(1-s[:,:int(s.size(1)*ratio)]+EPS).mean()\n",
    "    return res\n",
    "\n",
    "\n",
    "def consist_loss(s):\n",
    "    if len(s) == 0:\n",
    "        return 0\n",
    "    s = torch.sigmoid(s)\n",
    "    W = torch.ones(s.shape[0],s.shape[0])\n",
    "    D = torch.eye(s.shape[0])*torch.sum(W,dim=1)\n",
    "    L = D-W\n",
    "    L = L.to(device)\n",
    "    res = torch.trace(torch.transpose(s,0,1) @ L @ s)/(s.shape[0]*s.shape[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935d0d70-7854-41d8-9e8b-adf62c717333",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Network Training Function#####################################\n",
    "def train(epoch):\n",
    "    print('train...........')\n",
    "    scheduler.step()\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(\"LR\", param_group['lr'])\n",
    "    model.train()\n",
    "    s1_list = []\n",
    "    s2_list = []\n",
    "    loss_all = 0\n",
    "    step = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data.x.shape, data.edge_index.shape, data.batch.shape, data.edge_attr.shape, data.pos.shape)\n",
    "        output, w1, w2, s1, s2 = model(data.x, data.edge_index, data.batch, data.edge_attr, data.pos)\n",
    "        s1_list.append(s1.view(-1).detach().cpu().numpy())\n",
    "        s2_list.append(s2.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        loss_c = F.nll_loss(output, data.y)\n",
    "\n",
    "        loss_p1 = (torch.norm(w1, p=2)-1) ** 2\n",
    "        loss_p2 = (torch.norm(w2, p=2)-1) ** 2\n",
    "        loss_tpk1 = topk_loss(s1,ratio)\n",
    "        loss_tpk2 = topk_loss(s2,ratio)\n",
    "        loss_consist = 0\n",
    "        for c in range(nclass):\n",
    "            loss_consist += consist_loss(s1[data.y == c])\n",
    "        loss = lamb0*loss_c + lamb1 * loss_p1 + lamb2 * loss_p2 \\\n",
    "                   + lamb3 * loss_tpk1 + lamb4 *loss_tpk2 + lamb5* loss_consist\n",
    "        writer.add_scalar('train/classification_loss', loss_c, epoch*len(train_loader)+step)\n",
    "        writer.add_scalar('train/unit_loss1', loss_p1, epoch*len(train_loader)+step)\n",
    "        writer.add_scalar('train/unit_loss2', loss_p2, epoch*len(train_loader)+step)\n",
    "        writer.add_scalar('train/TopK_loss1', loss_tpk1, epoch*len(train_loader)+step)\n",
    "        writer.add_scalar('train/TopK_loss2', loss_tpk2, epoch*len(train_loader)+step)\n",
    "        writer.add_scalar('train/GCL_loss', loss_consist, epoch*len(train_loader)+step)\n",
    "        step = step + 1\n",
    "\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "\n",
    "        s1_arr = np.hstack(s1_list)\n",
    "        s2_arr = np.hstack(s2_list)\n",
    "    return loss_all / len(train_loader.dataset), s1_arr, s2_arr ,w1,w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a3d69ce-8d89-4d3d-8010-d6a9960829cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Network Testing Function#####################################\n",
    "def test_acc(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        outputs= model(data.x, data.edge_index, data.batch, data.edge_attr,data.pos)\n",
    "        pred = outputs[0].max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "def test_loss(loader,epoch):\n",
    "    print('testing...........')\n",
    "    model.eval()\n",
    "    loss_all = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output, w1, w2, s1, s2= model(data.x, data.edge_index, data.batch, data.edge_attr,data.pos)\n",
    "        loss_c = F.nll_loss(output, data.y)\n",
    "\n",
    "        loss_p1 = (torch.norm(w1, p=2)-1) ** 2\n",
    "        loss_p2 = (torch.norm(w2, p=2)-1) ** 2\n",
    "        loss_tpk1 = topk_loss(s1,ratio)\n",
    "        loss_tpk2 = topk_loss(s2,ratio)\n",
    "        loss_consist = 0\n",
    "        for c in range(nclass):\n",
    "            loss_consist += consist_loss(s1[data.y == c])\n",
    "        loss = lamb0*loss_c + lamb1 * loss_p1 + lamb2 * loss_p2 \\\n",
    "                   + lamb3 * loss_tpk1 + lamb4 *loss_tpk2 + lamb5* loss_consist\n",
    "\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "    return loss_all / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab05bd43-96e3-4a9a-b8b5-9ace855daa6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]/isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages/torch_sparse/matmul.py:97: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  C = torch.sparse.mm(A, B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                         | 1/50 [01:24<1:09:16, 84.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 000, Train Loss: 0.3549234, Train Acc: 0.9987500, Test Loss: 0.3043759, Test Acc: 0.9925000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                        | 2/50 [02:49<1:07:33, 84.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 001, Train Loss: 0.2838438, Train Acc: 1.0000000, Test Loss: 0.2857170, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▌                                       | 3/50 [04:13<1:06:11, 84.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 002, Train Loss: 0.2897270, Train Acc: 1.0000000, Test Loss: 0.2772897, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                      | 4/50 [05:37<1:04:31, 84.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 003, Train Loss: 0.2837013, Train Acc: 1.0000000, Test Loss: 0.2765642, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 5/50 [07:01<1:03:14, 84.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 004, Train Loss: 0.2823916, Train Acc: 1.0000000, Test Loss: 0.2730281, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████                                     | 6/50 [08:25<1:01:37, 84.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 23s\n",
      "Epoch: 005, Train Loss: 0.2816558, Train Acc: 1.0000000, Test Loss: 0.2744561, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▉                                    | 7/50 [09:49<1:00:09, 83.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 006, Train Loss: 0.2802653, Train Acc: 0.9996875, Test Loss: 0.2841199, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████                                     | 8/50 [11:12<58:44, 83.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 007, Train Loss: 0.2803519, Train Acc: 1.0000000, Test Loss: 0.2748316, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▉                                    | 9/50 [12:36<57:22, 83.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 008, Train Loss: 0.2828178, Train Acc: 1.0000000, Test Loss: 0.2734080, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 10/50 [14:00<55:48, 83.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 23s\n",
      "Epoch: 009, Train Loss: 0.2818608, Train Acc: 1.0000000, Test Loss: 0.2786739, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████▍                                 | 11/50 [15:23<54:21, 83.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 23s\n",
      "Epoch: 010, Train Loss: 0.2815066, Train Acc: 1.0000000, Test Loss: 0.2737440, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▎                                | 12/50 [16:47<53:00, 83.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 011, Train Loss: 0.2806052, Train Acc: 1.0000000, Test Loss: 0.2727917, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████▏                               | 13/50 [18:09<51:20, 83.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 22s\n",
      "Epoch: 012, Train Loss: 0.2827597, Train Acc: 1.0000000, Test Loss: 0.2753450, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████                               | 14/50 [19:35<50:29, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 26s\n",
      "Epoch: 013, Train Loss: 0.3010444, Train Acc: 0.4971875, Test Loss: 3.8186395, Test Acc: 0.5112500\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 15/50 [21:00<49:04, 84.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 014, Train Loss: 0.3023470, Train Acc: 1.0000000, Test Loss: 0.2785918, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▊                             | 16/50 [22:23<47:30, 83.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 23s\n",
      "Epoch: 015, Train Loss: 0.2978334, Train Acc: 1.0000000, Test Loss: 0.2757992, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████▌                            | 17/50 [23:47<46:10, 83.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 016, Train Loss: 0.2947561, Train Acc: 0.9978125, Test Loss: 0.2888053, Test Acc: 0.9987500\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▍                           | 18/50 [25:11<44:43, 83.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 017, Train Loss: 0.2882331, Train Acc: 1.0000000, Test Loss: 0.2725222, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.01\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▎                          | 19/50 [26:35<43:24, 84.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 018, Train Loss: 0.2942500, Train Acc: 0.8509375, Test Loss: 0.6067780, Test Acc: 0.8400000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 20/50 [27:59<41:58, 83.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 019, Train Loss: 0.2901023, Train Acc: 1.0000000, Test Loss: 0.2726586, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████                         | 21/50 [29:23<40:36, 84.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 020, Train Loss: 0.2920216, Train Acc: 1.0000000, Test Loss: 0.2727059, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████▉                        | 22/50 [30:47<39:14, 84.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 021, Train Loss: 0.2912413, Train Acc: 1.0000000, Test Loss: 0.2730627, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████▊                       | 23/50 [32:11<37:51, 84.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 022, Train Loss: 0.2870683, Train Acc: 1.0000000, Test Loss: 0.2729371, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▋                      | 24/50 [33:35<36:24, 84.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 023, Train Loss: 0.2872020, Train Acc: 1.0000000, Test Loss: 0.2734885, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 25/50 [34:59<34:59, 83.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 024, Train Loss: 0.2852886, Train Acc: 1.0000000, Test Loss: 0.2739827, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████▎                    | 26/50 [36:23<33:36, 84.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 025, Train Loss: 0.2835697, Train Acc: 0.9596875, Test Loss: 0.3792204, Test Acc: 0.9625000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████▏                   | 27/50 [37:48<32:15, 84.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 026, Train Loss: 0.2902931, Train Acc: 1.0000000, Test Loss: 0.2731194, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████                   | 28/50 [39:12<30:52, 84.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 027, Train Loss: 0.2836728, Train Acc: 0.9984375, Test Loss: 0.2873803, Test Acc: 0.9987500\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████▉                  | 29/50 [40:36<29:25, 84.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 028, Train Loss: 0.2906398, Train Acc: 0.8209375, Test Loss: 0.6300485, Test Acc: 0.8075000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 30/50 [42:00<28:03, 84.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 029, Train Loss: 0.2873565, Train Acc: 1.0000000, Test Loss: 0.2735180, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████▋                | 31/50 [43:25<26:45, 84.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 030, Train Loss: 0.2897810, Train Acc: 1.0000000, Test Loss: 0.2748016, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▌               | 32/50 [44:50<25:21, 84.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 031, Train Loss: 0.2880240, Train Acc: 1.0000000, Test Loss: 0.2746967, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████▍              | 33/50 [46:14<23:56, 84.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 032, Train Loss: 0.2871336, Train Acc: 1.0000000, Test Loss: 0.2725882, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████▏             | 34/50 [47:38<22:30, 84.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 033, Train Loss: 0.2841243, Train Acc: 1.0000000, Test Loss: 0.2728500, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 35/50 [49:02<21:01, 84.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 23s\n",
      "Epoch: 034, Train Loss: 0.2840514, Train Acc: 1.0000000, Test Loss: 0.2735100, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████▉            | 36/50 [50:26<19:36, 84.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 035, Train Loss: 0.2951676, Train Acc: 1.0000000, Test Loss: 0.2737916, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▊           | 37/50 [51:50<18:13, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 036, Train Loss: 0.2890276, Train Acc: 1.0000000, Test Loss: 0.2768392, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████▋          | 38/50 [53:14<16:48, 84.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 037, Train Loss: 0.2873326, Train Acc: 0.9800000, Test Loss: 0.3503828, Test Acc: 0.9712500\n",
      "train...........\n",
      "LR 0.005\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████▌         | 39/50 [54:40<15:30, 84.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 26s\n",
      "Epoch: 038, Train Loss: 0.2925406, Train Acc: 1.0000000, Test Loss: 0.2741944, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 40/50 [56:04<14:03, 84.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 039, Train Loss: 0.2861013, Train Acc: 1.0000000, Test Loss: 0.2744457, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████▎       | 41/50 [57:28<12:38, 84.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 040, Train Loss: 0.2841186, Train Acc: 1.0000000, Test Loss: 0.2740462, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████       | 42/50 [58:52<11:13, 84.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 041, Train Loss: 0.2834029, Train Acc: 1.0000000, Test Loss: 0.2734129, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▎     | 43/50 [1:00:16<09:48, 84.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 042, Train Loss: 0.2948051, Train Acc: 1.0000000, Test Loss: 0.2734307, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████     | 44/50 [1:01:41<08:26, 84.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 043, Train Loss: 0.2924775, Train Acc: 1.0000000, Test Loss: 0.2735408, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████▉    | 45/50 [1:03:06<07:02, 84.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 25s\n",
      "Epoch: 044, Train Loss: 0.2955792, Train Acc: 0.9990625, Test Loss: 0.2860202, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████▋   | 46/50 [1:04:30<05:37, 84.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 045, Train Loss: 0.2918843, Train Acc: 1.0000000, Test Loss: 0.2730324, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████▌  | 47/50 [1:05:54<04:13, 84.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 046, Train Loss: 0.2982701, Train Acc: 1.0000000, Test Loss: 0.2723415, Test Acc: 1.0000000\n",
      "saving best model\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▎ | 48/50 [1:07:19<02:48, 84.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 047, Train Loss: 0.2942685, Train Acc: 1.0000000, Test Loss: 0.2735231, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████▏| 49/50 [1:08:43<01:24, 84.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 048, Train Loss: 0.3009625, Train Acc: 1.0000000, Test Loss: 0.2734786, Test Acc: 1.0000000\n",
      "train...........\n",
      "LR 0.0025\n",
      "testing...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 50/50 [1:10:07<00:00, 84.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*====**\n",
      "1m 24s\n",
      "Epoch: 049, Train Loss: 0.3052767, Train Acc: 1.0000000, Test Loss: 0.2732146, Test Acc: 1.0000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       409\n",
      "           1       1.00      1.00      1.00       391\n",
      "\n",
      "    accuracy                           1.00       800\n",
      "   macro avg       1.00      1.00      1.00       800\n",
      "weighted avg       1.00      1.00      1.00       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "############################   Model Training #########################################\n",
    "#######################################################################################\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = 1e10\n",
    "for epoch in tqdm(range(0, num_epoch)):\n",
    "    since  = time.time()\n",
    "    tr_loss, s1_arr, s2_arr, w1, w2 = train(epoch)\n",
    "    tr_acc = test_acc(train_loader)\n",
    "    val_acc = test_acc(val_loader)\n",
    "    val_loss = test_loss(val_loader,epoch)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('*====**')\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "          'Train Acc: {:.7f}, Test Loss: {:.7f}, Test Acc: {:.7f}'.format(epoch, tr_loss,\n",
    "                                                       tr_acc, val_loss, val_acc))\n",
    "\n",
    "    writer.add_scalars('Acc',{'train_acc':tr_acc,'val_acc':val_acc},  epoch)\n",
    "    writer.add_scalars('Loss', {'train_loss': tr_loss, 'val_loss': val_loss},  epoch)\n",
    "    writer.add_histogram('Hist/hist_s1', s1_arr, epoch)\n",
    "    writer.add_histogram('Hist/hist_s2', s2_arr, epoch)\n",
    "\n",
    "    if val_loss < best_loss and epoch > 5:\n",
    "        print(\"saving best model\")\n",
    "        best_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if save_model:\n",
    "            torch.save(best_model_wts, os.path.join(save_path,str(fold)+'.pth'))\n",
    "\n",
    "#######################################################################################\n",
    "######################### Testing on testing set ######################################\n",
    "#######################################################################################\n",
    "\n",
    "if load_model:\n",
    "    model = Network(indim,ratio,nclass, R = nroi, k =3).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_path,str(fold)+'.pth')))\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    correct = 0\n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        outputs= model(data.x, data.edge_index, data.batch, data.edge_attr,data.pos)\n",
    "        pred = outputs[0].max(1)[1]\n",
    "        preds.append(pred.cpu().detach().numpy())\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    preds = np.concatenate(preds,axis=0)\n",
    "    trues = np.array([example.y.cpu().detach().numpy() for example in val_loader.dataset], dtype = np.uint8)\n",
    "    cm = confusion_matrix(trues,preds)\n",
    "    print(\"Confusion matrix\")\n",
    "    print(classification_report(trues, preds))\n",
    "\n",
    "else:\n",
    "   model.load_state_dict(best_model_wts)\n",
    "   model.eval()\n",
    "   test_accuracy = test_acc(val_loader)\n",
    "   test_l= test_loss(val_loader,0)\n",
    "   print(\"===========================\")\n",
    "   print(\"Test Acc: {:.7f}, Test Loss: {:.7f} \".format(test_accuracy, test_l))\n",
    "   print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec121cb-4535-4ddf-a9a0-656fb55029cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (n1): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=960, bias=True)\n",
      "  )\n",
      "  (conv1): MyNNConv(30, 32)\n",
      "  (pool1): TopKPooling(32, ratio=0.5, multiplier=1)\n",
      "  (n2): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=3, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3, out_features=1024, bias=True)\n",
      "  )\n",
      "  (conv2): MyNNConv(32, 32)\n",
      "  (pool2): TopKPooling(32, ratio=0.5, multiplier=1)\n",
      "  (fc1): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
      "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61cde860-d4dc-466c-88dc-84c9cbd91ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.3255e-41,  1.1734e-41,  3.2900e-41,  3.3522e-41, -4.2237e-41,\n",
      "          3.9100e-41, -1.8960e-41, -2.5406e-42,  2.0054e-41, -1.1526e-41,\n",
      "         -1.6115e-43, -3.7081e-41, -4.8094e-41, -1.2750e-41, -1.3672e-41,\n",
      "         -1.4742e-41, -1.6080e-41, -4.5609e-41, -6.8930e-42, -5.4527e-41,\n",
      "          4.1513e-41,  9.1225e-42,  8.0364e-42, -1.0144e-41,  3.2880e-41,\n",
      "          3.1427e-41, -3.4905e-41, -4.0022e-41,  3.6214e-41, -3.4521e-41],\n",
      "        [-2.6891e-42,  1.6684e-41, -1.5241e-41, -2.7984e-42,  8.9292e-41,\n",
      "         -9.4097e-42, -1.8546e-40, -5.4404e-41, -2.9713e-41,  6.5132e-42,\n",
      "          1.5014e-40,  8.9623e-41, -3.8115e-41,  1.7742e-41,  1.0363e-40,\n",
      "         -4.5291e-41, -3.6514e-41, -5.0712e-41, -1.1803e-41, -6.1825e-42,\n",
      "          3.3193e-39,  6.9152e-39,  1.4285e-40, -9.6657e-41, -4.0087e-41,\n",
      "          8.9346e-40,  1.0078e-39,  4.1560e-41,  2.5691e-40,  2.2647e-40],\n",
      "        [-1.2163e-40,  3.0323e-41,  5.7439e-42, -1.0812e-41, -4.2947e-41,\n",
      "         -2.1258e-41, -9.2128e-41, -2.2070e-41,  1.0817e-41, -1.7823e-41,\n",
      "         -2.0658e-41, -1.2044e-41, -2.5722e-41, -2.1227e-41, -2.7781e-41,\n",
      "         -2.0893e-41, -4.2985e-41,  1.3975e-41, -4.9960e-41, -4.5290e-42,\n",
      "         -3.0261e-41, -8.5970e-42,  5.1045e-41,  2.4427e-41,  2.1493e-41,\n",
      "         -3.4611e-41, -3.0590e-42, -3.2753e-41, -3.4084e-41, -3.4368e-41]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.8495e-42,  1.0095e-41,  2.4228e-41],\n",
      "        [-3.9128e-41, -8.7343e-42, -2.1382e-41],\n",
      "        [ 3.8623e-41,  1.6224e-41,  1.0291e-41],\n",
      "        ...,\n",
      "        [-4.6993e-41,  3.9606e-41, -2.5223e-42],\n",
      "        [ 1.2288e-41, -3.2380e-41, -2.5729e-41],\n",
      "        [-2.0578e-41,  1.6597e-41, -3.6348e-41]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 5.6462e-04,  5.6948e-03,  6.6531e-02, -5.1843e-03,  1.5221e-02,\n",
      "         9.6028e-04,  1.8038e-02, -2.6996e-02,  1.3655e-02,  2.1120e-03,\n",
      "        -1.5205e-04, -1.3676e-01,  2.2966e-02,  5.3119e-02,  2.1023e-02,\n",
      "        -7.5611e-04,  1.2436e-02,  3.9549e-02,  2.3320e-02, -1.0231e-01,\n",
      "         3.0992e-05,  2.9164e-03,  4.2364e-03,  4.9241e-02, -6.8359e-03,\n",
      "         7.2950e-03,  3.3745e-03,  2.5244e-02, -3.4608e-03,  1.3207e-02,\n",
      "         1.2325e-02,  9.4563e-03,  1.1019e-03,  6.8460e-03,  1.0277e-01,\n",
      "         1.5333e-03,  2.1255e-02,  1.9846e-02,  2.9759e-02, -3.8342e-03,\n",
      "         9.0197e-03,  2.7682e-03, -8.2973e-05, -5.6982e-02,  2.8230e-02,\n",
      "         7.2159e-02,  3.6516e-02, -2.4036e-04,  1.7940e-02,  5.0655e-02,\n",
      "         3.7653e-02, -2.7427e-02,  6.9961e-05,  5.5968e-03,  3.4845e-03,\n",
      "         6.3499e-02,  7.1650e-03,  2.2194e-02,  3.3263e-03,  2.4006e-02,\n",
      "        -2.6940e-03,  1.8604e-02,  1.6587e-02, -1.2939e-03, -9.0223e-05,\n",
      "         3.2038e-03,  4.8034e-02, -3.0861e-03,  6.2578e-03, -3.3719e-03,\n",
      "         1.2591e-02, -6.7189e-02, -1.6631e-03,  2.7773e-03, -2.8238e-05,\n",
      "        -1.8036e-01,  1.2604e-02,  2.6512e-02,  1.2828e-02, -8.8225e-05,\n",
      "         3.5015e-03,  2.2252e-02,  1.3344e-02, -1.3020e-01, -5.9054e-05,\n",
      "         4.4596e-03,  5.0435e-03,  6.0175e-02, -8.1071e-03,  3.6429e-03,\n",
      "         3.2065e-03,  2.4787e-02, -6.1795e-04,  1.1181e-02,  1.1786e-02,\n",
      "         5.3299e-03,  1.4474e-03,  5.7182e-03,  5.7960e-02,  3.7584e-03,\n",
      "         1.9306e-02,  4.0406e-02,  1.8233e-02, -1.8842e-02,  2.6060e-02,\n",
      "         3.3487e-03,  9.8583e-05, -1.3680e-01,  3.6470e-02,  5.5187e-02,\n",
      "         2.2164e-02,  8.1072e-04,  1.0492e-02,  3.5588e-02,  2.6454e-02,\n",
      "        -1.0875e-01,  3.0350e-06,  8.0467e-03,  1.7682e-03,  4.5383e-02,\n",
      "         1.0499e-02,  1.6345e-02,  3.6055e-03,  1.9520e-02, -5.0587e-03,\n",
      "         1.9593e-02,  1.3040e-02,  2.9393e-03, -6.7742e-05,  1.9597e-03,\n",
      "         4.6356e-02, -8.5049e-03,  3.8652e-03, -1.1319e-02,  5.3911e-03,\n",
      "        -5.6805e-02, -5.1141e-04,  1.6628e-03, -3.2044e-05, -1.7971e-01,\n",
      "         1.3053e-02,  2.8630e-02,  7.1625e-03, -1.7112e-04, -1.3610e-03,\n",
      "         1.7373e-02,  5.6967e-03, -1.3467e-01, -7.9463e-06,  2.1537e-03,\n",
      "         4.5303e-03,  5.7466e-02, -3.5447e-03, -7.3727e-03,  3.4564e-03,\n",
      "         2.3330e-02, -4.1899e-03,  6.8654e-03,  1.2097e-02,  7.0215e-03,\n",
      "         1.9224e-05,  4.7302e-03,  6.9202e-02, -2.3801e-03,  1.7886e-02,\n",
      "         5.2328e-02,  2.0635e-02, -5.7370e-02,  1.9789e-02,  2.4715e-03,\n",
      "        -9.4776e-05, -1.1306e-01,  2.4768e-02,  3.6891e-02,  2.5187e-02,\n",
      "        -4.9637e-04,  1.0894e-02,  3.8058e-02,  2.3580e-02, -7.8262e-02,\n",
      "        -3.6824e-05,  3.5001e-03,  4.0969e-03,  5.0147e-02, -1.2769e-02,\n",
      "         1.3599e-02,  2.4207e-03,  2.4133e-02, -2.5032e-03,  1.4401e-02,\n",
      "         1.1780e-02,  2.9861e-03,  7.1838e-04,  4.5149e-03,  7.3171e-02,\n",
      "         1.0300e-03,  1.6790e-02,  4.1551e-02,  1.7730e-02, -1.3863e-02,\n",
      "         1.5314e-02,  2.0396e-03, -1.2137e-04, -9.8399e-02,  3.0349e-02,\n",
      "         5.2166e-02,  2.6496e-02, -7.1924e-04,  1.1858e-02,  3.9699e-02,\n",
      "         2.6744e-02, -6.7673e-02, -1.8549e-05,  3.6375e-03,  2.7047e-03,\n",
      "         4.7201e-02, -3.8024e-03,  1.4788e-02,  2.0074e-03,  2.3732e-02,\n",
      "        -3.2728e-03,  1.4031e-02,  1.2438e-02,  3.9977e-03,  6.8439e-04,\n",
      "         4.1915e-03,  6.5633e-02, -2.7871e-03,  1.7479e-02,  4.4249e-02,\n",
      "         1.8790e-02, -2.2087e-02,  2.1062e-02,  2.2940e-03, -8.6327e-05,\n",
      "        -1.0773e-01,  3.2797e-02,  6.4358e-02,  1.8813e-02, -2.9646e-04,\n",
      "         1.0049e-02,  4.0190e-02,  2.8058e-02, -8.3453e-02,  4.5867e-05,\n",
      "         2.3109e-03,  2.1283e-03,  3.9262e-02,  7.9939e-03,  1.2175e-02,\n",
      "         2.4746e-03,  1.4495e-02, -4.5414e-03,  1.5601e-02,  1.2978e-02,\n",
      "         4.8863e-03,  9.5175e-04,  6.7010e-03,  7.9711e-02,  2.4792e-03,\n",
      "         2.0482e-02,  1.7916e-02,  3.0186e-02, -2.4921e-02,  1.0693e-02,\n",
      "         3.7633e-03, -2.5352e-05, -1.1361e-01,  2.8864e-02,  4.9343e-02,\n",
      "         3.0282e-02, -1.3560e-05,  1.7907e-02,  4.5883e-02,  3.4162e-02,\n",
      "        -7.8136e-02,  8.3986e-05,  7.9592e-03,  2.7934e-03,  5.6872e-02,\n",
      "        -9.4631e-05,  2.2210e-02,  3.4619e-03,  2.7909e-02, -1.8368e-03,\n",
      "         2.2784e-02,  1.4927e-02, -2.7037e-03,  1.0768e-03,  6.5132e-03,\n",
      "         9.5922e-02,  9.5348e-04,  2.0153e-02,  3.8948e-02,  2.5882e-02,\n",
      "        -1.6177e-02,  3.9447e-03,  3.0036e-03, -3.4468e-05, -1.1136e-01,\n",
      "         2.9170e-02,  6.6940e-02,  3.5171e-02,  1.2055e-04,  2.0295e-02,\n",
      "         5.2438e-02,  3.6273e-02, -7.7038e-02,  8.1743e-05,  5.2324e-03,\n",
      "         3.0402e-03,  4.9331e-02,  4.9705e-03,  1.6215e-02,  2.3200e-03,\n",
      "         2.8027e-02, -3.0014e-04,  1.5905e-02,  1.3895e-02,  3.2096e-03,\n",
      "        -9.9330e-04, -8.8676e-03, -2.1803e-01, -9.1248e-03, -3.9965e-02,\n",
      "        -5.9671e-02, -7.3579e-02,  7.3227e-02, -1.5246e-02, -4.9952e-03,\n",
      "        -2.9779e-05,  1.8503e-01, -5.2241e-02, -8.9818e-02, -8.7777e-02,\n",
      "        -3.5654e-04, -3.9431e-02, -1.0241e-01, -8.8399e-02,  1.1538e-01,\n",
      "        -1.4885e-04, -1.0637e-02, -4.5872e-03, -1.1402e-01,  4.2010e-03,\n",
      "        -5.6915e-02, -6.3443e-03, -5.4939e-02, -4.8152e-03, -5.4096e-02,\n",
      "        -2.3582e-02, -1.9297e-03, -2.9622e-03, -1.1522e-02, -1.7118e-01,\n",
      "        -7.9806e-03, -3.3585e-02, -5.4930e-02, -5.6371e-02,  5.6287e-02,\n",
      "        -2.7644e-02, -5.2853e-03, -1.2051e-04,  2.0964e-01, -4.8919e-02,\n",
      "        -7.7699e-02, -7.3055e-02, -5.1849e-04, -2.0539e-02, -8.3357e-02,\n",
      "        -6.5556e-02,  1.3091e-01, -1.2982e-04, -1.2886e-02, -8.9632e-03,\n",
      "        -9.3936e-02,  2.7578e-03, -4.9390e-02, -7.3644e-03, -5.1884e-02,\n",
      "         2.4324e-03, -4.5366e-02, -2.1577e-02, -1.4650e-02, -2.5458e-03,\n",
      "        -1.0252e-02, -1.5840e-01, -3.4863e-03, -3.1232e-02, -4.6179e-02,\n",
      "        -4.9225e-02,  6.8088e-02, -2.6765e-02, -4.7434e-03,  9.5870e-05,\n",
      "         2.7341e-01, -4.7679e-02, -8.0544e-02, -6.6930e-02,  8.3155e-04,\n",
      "        -2.0261e-02, -7.9217e-02, -5.9746e-02,  1.9054e-01, -1.6716e-04,\n",
      "        -9.4492e-03, -9.9132e-03, -9.6811e-02,  1.0576e-03, -4.0891e-02,\n",
      "        -7.1497e-03, -4.9781e-02,  2.7919e-03, -4.1424e-02, -2.3612e-02,\n",
      "        -1.4575e-02, -7.7220e-04, -4.1630e-03, -1.1966e-01, -4.7594e-03,\n",
      "        -2.0208e-02, -5.1255e-02, -3.2943e-02,  4.5188e-02, -9.1993e-03,\n",
      "        -2.0785e-03, -2.2127e-05, -6.1411e-02, -2.7763e-02, -4.5025e-02,\n",
      "        -4.1268e-02, -4.6386e-04, -1.4775e-02, -5.1367e-02, -3.9788e-02,\n",
      "        -4.0734e-02, -7.9321e-05, -5.0690e-03, -4.4053e-03, -5.7844e-02,\n",
      "         5.4376e-03, -2.7953e-02, -3.7808e-03, -3.0905e-02, -1.4315e-03,\n",
      "        -2.4840e-02, -1.0400e-02, -9.4821e-03, -2.4207e-03, -1.8328e-02,\n",
      "        -2.3111e-01, -2.1191e-02, -6.2523e-02, -9.0146e-02, -1.0080e-01,\n",
      "         2.7177e-02, -3.2397e-02, -8.7952e-03,  6.0016e-05,  1.5877e-01,\n",
      "        -7.0722e-02, -1.1731e-01, -1.0649e-01, -1.5934e-04, -6.2102e-02,\n",
      "        -1.1948e-01, -1.1288e-01,  9.9816e-02, -3.4062e-04, -1.8770e-02,\n",
      "        -3.6852e-03, -1.0369e-01, -5.8488e-03, -8.6197e-02, -7.3728e-03,\n",
      "        -7.1419e-02, -4.4199e-03, -6.7911e-02, -3.4713e-02,  1.7808e-03,\n",
      "         1.5863e-03, -5.1873e-03, -1.4481e-01, -2.7171e-03, -2.5673e-02,\n",
      "        -5.1310e-02, -4.4115e-02,  5.4787e-03, -1.1165e-02, -8.2016e-04,\n",
      "         8.4571e-04, -4.5062e-02, -3.2960e-02, -5.4074e-02, -5.2626e-02,\n",
      "         5.7521e-03, -1.8959e-02, -5.7665e-02, -4.4446e-02, -2.9040e-02,\n",
      "        -1.9732e-04,  6.0342e-03, -8.2356e-03, -5.6936e-02,  4.0281e-02,\n",
      "        -2.7673e-02,  7.5471e-04, -3.0611e-02, -1.7865e-03, -1.8954e-02,\n",
      "        -1.9803e-02, -1.4107e-02, -2.8132e-03, -8.2117e-03, -1.2609e-01,\n",
      "         9.1604e-04, -2.1776e-02, -3.9184e-02, -3.3963e-02,  8.4876e-02,\n",
      "        -2.6341e-02, -4.0727e-03,  3.2699e-05,  3.0737e-01, -3.8425e-02,\n",
      "        -5.6336e-02, -5.1776e-02,  4.9056e-04, -4.5508e-03, -6.1547e-02,\n",
      "        -4.1553e-02,  2.3021e-01, -2.0975e-05, -8.5050e-03, -1.1079e-02,\n",
      "        -8.5716e-02,  2.7939e-03, -2.6747e-02, -7.3945e-03, -4.1459e-02,\n",
      "         2.6890e-03, -3.4088e-02, -1.7143e-02, -3.0464e-02,  4.8366e-05,\n",
      "        -3.1571e-03, -1.2090e-01,  2.8484e-03, -1.3390e-02, -3.2555e-02,\n",
      "        -2.6546e-02,  2.3218e-02, -3.3586e-03, -9.4557e-05,  1.7913e-04,\n",
      "        -6.2793e-02, -2.1376e-02, -4.3303e-02, -4.1670e-02,  1.4774e-03,\n",
      "        -1.1303e-02, -3.6564e-02, -2.4585e-02, -4.3933e-02, -2.0265e-04,\n",
      "         3.4876e-03, -6.0046e-03, -5.5661e-02,  2.0161e-02, -1.4323e-02,\n",
      "         1.3338e-03, -2.2962e-02, -1.6361e-03, -9.8285e-03, -1.0731e-02,\n",
      "        -1.2473e-02, -1.0308e-03, -8.7782e-03, -1.7325e-01, -4.3393e-03,\n",
      "        -3.1972e-02, -5.4234e-02, -5.5507e-02,  7.3607e-02, -2.2395e-02,\n",
      "        -4.1986e-03,  2.2722e-05,  2.1278e-01, -4.6810e-02, -7.5490e-02,\n",
      "        -6.6324e-02,  1.0787e-04, -2.3148e-02, -8.2444e-02, -6.8749e-02,\n",
      "         1.4230e-01, -1.3592e-04, -9.1863e-03, -7.2439e-03, -9.4731e-02,\n",
      "         5.2132e-03, -4.3343e-02, -5.8447e-03, -4.8240e-02, -1.1739e-03,\n",
      "        -4.3997e-02, -2.1314e-02, -1.5344e-02, -5.4253e-03, -1.6213e-02,\n",
      "        -1.9022e-01, -1.7747e-02, -4.7579e-02, -7.9548e-02, -7.4825e-02,\n",
      "         1.8441e-02, -4.5418e-02, -7.4995e-03, -1.7928e-04,  2.2191e-01,\n",
      "        -6.1217e-02, -1.0194e-01, -8.5530e-02, -1.5045e-03, -3.9351e-02,\n",
      "        -1.0240e-01, -9.2489e-02,  1.5794e-01, -1.6440e-04, -1.9052e-02,\n",
      "        -4.6609e-03, -7.9863e-02, -3.8119e-02, -6.8311e-02, -9.0378e-03,\n",
      "        -5.8600e-02,  3.3562e-03, -6.1309e-02, -2.4978e-02, -1.5885e-02,\n",
      "         1.5738e-03,  9.1591e-03,  9.9770e-02,  2.4834e-04,  2.7298e-02,\n",
      "         4.2292e-02,  4.1643e-02, -1.9344e-02,  1.4400e-02,  3.4719e-03,\n",
      "        -8.1530e-05, -7.7931e-02,  2.7154e-02,  6.8518e-02,  5.2636e-02,\n",
      "        -5.8538e-04,  2.6200e-02,  5.1159e-02,  4.4999e-02, -6.5481e-02,\n",
      "         7.5050e-05,  7.6785e-03,  3.8811e-03,  4.3440e-02, -6.6527e-03,\n",
      "         2.4022e-02,  3.9234e-03,  1.7795e-02,  3.1682e-03,  2.9547e-02,\n",
      "         1.4253e-02,  1.5736e-03,  1.0095e-03,  1.0134e-02,  1.2202e-01,\n",
      "         1.2547e-02,  3.1042e-02,  5.5711e-02,  5.6895e-02, -8.2102e-03,\n",
      "         1.7187e-02,  4.2947e-03,  2.2905e-05, -6.2420e-02,  3.3239e-02,\n",
      "         4.7883e-02,  6.8817e-02,  8.6611e-05,  3.1077e-02,  6.9870e-02,\n",
      "         6.4227e-02, -2.9261e-02,  8.7117e-05,  1.1242e-02,  4.8447e-03,\n",
      "         5.3292e-02, -1.1996e-02,  5.0474e-02,  4.5186e-03,  3.4101e-02,\n",
      "         1.0651e-03,  3.9349e-02,  1.4534e-02, -3.8921e-03,  1.7401e-03,\n",
      "         8.6595e-03,  6.5916e-02,  9.6404e-03,  2.3622e-02,  3.5625e-02,\n",
      "         3.3069e-02, -2.6933e-02,  2.1669e-02,  3.0059e-03,  3.2296e-05,\n",
      "        -1.6372e-01,  1.8855e-02,  1.5069e-02,  4.5569e-02,  2.8083e-04,\n",
      "         1.4979e-02,  4.0071e-02,  2.9881e-02, -1.3282e-01, -3.4971e-05,\n",
      "         9.1403e-03,  3.7257e-03,  3.3691e-02, -9.1477e-04,  3.3946e-02,\n",
      "         4.3908e-03,  3.0775e-02,  3.2078e-05,  2.7514e-02,  9.7330e-03,\n",
      "         5.1145e-03,  1.1460e-03,  3.6641e-03,  5.3942e-02, -9.8586e-03,\n",
      "         1.3596e-02,  9.0549e-03,  1.1178e-02, -6.2683e-02,  1.8378e-02,\n",
      "         1.0019e-03, -1.9139e-04, -2.2071e-01,  1.5123e-02,  1.8615e-02,\n",
      "         2.8670e-02, -9.2431e-04,  3.3921e-03,  1.9752e-02,  7.3157e-03,\n",
      "        -1.6379e-01, -4.1484e-05, -3.6419e-03,  4.7747e-03,  4.1757e-02,\n",
      "         9.6675e-04, -5.2204e-04,  2.5110e-03,  1.7429e-02, -4.6454e-04,\n",
      "         9.8200e-03,  9.8465e-03,  1.5136e-02,  2.0688e-03,  7.1313e-03,\n",
      "         6.2611e-02,  2.8447e-03,  2.3049e-02,  5.5026e-02,  2.4036e-02,\n",
      "        -1.4256e-02,  3.1120e-02,  2.4455e-03,  7.9361e-05, -1.4767e-01,\n",
      "         2.3194e-02,  4.1086e-02,  3.6446e-02,  7.1392e-04,  1.3472e-02,\n",
      "         3.3740e-02,  2.7281e-02, -1.2609e-01,  4.9884e-05,  3.1138e-03,\n",
      "         3.6236e-03,  2.9510e-02,  8.6503e-03,  1.4998e-02,  4.5137e-03,\n",
      "         2.2357e-02,  1.2266e-04,  2.2102e-02,  1.1303e-02,  6.2318e-03,\n",
      "         1.2568e-03,  9.3437e-03,  1.0344e-01,  6.5684e-03,  2.2715e-02,\n",
      "         3.5160e-02,  5.1799e-02, -1.8455e-02,  6.9049e-03,  4.6340e-03,\n",
      "         3.6067e-05, -9.4220e-02,  2.4743e-02,  3.5374e-02,  5.8058e-02,\n",
      "         4.8583e-04,  2.5231e-02,  6.1657e-02,  5.5586e-02, -6.5610e-02,\n",
      "         6.9755e-05,  9.7030e-03,  4.1764e-03,  4.6350e-02,  3.8254e-03,\n",
      "         3.7415e-02,  4.1814e-03,  2.8253e-02,  1.0200e-03,  3.1884e-02,\n",
      "         1.3809e-02, -1.9959e-04,  1.4796e-03,  6.1729e-03,  5.8916e-02,\n",
      "         2.2070e-03,  1.7118e-02,  3.5513e-02,  2.4230e-02, -4.1251e-02,\n",
      "         2.0787e-02,  2.9513e-03, -6.4707e-05, -1.7673e-01,  1.8898e-02,\n",
      "         1.9204e-02,  3.7129e-02, -5.0516e-04,  8.4273e-03,  2.8143e-02,\n",
      "         2.3730e-02, -1.3862e-01, -4.0825e-05,  4.5504e-03,  5.3988e-03,\n",
      "         3.6962e-02, -1.1919e-03,  1.5747e-02,  4.0376e-03,  2.1442e-02,\n",
      "         8.7776e-04,  1.8455e-02,  9.4703e-03,  1.1996e-02,  1.9324e-03,\n",
      "         9.5626e-03,  1.0002e-01,  3.5021e-03,  2.8270e-02,  4.9321e-02,\n",
      "         4.6308e-02, -2.8211e-02,  1.1203e-02,  3.4433e-03,  8.9818e-05,\n",
      "        -9.9415e-02,  2.6141e-02,  6.0744e-02,  5.7562e-02,  5.8757e-04,\n",
      "         2.8824e-02,  5.7354e-02,  5.2771e-02, -7.4838e-02,  4.6615e-05,\n",
      "         8.4810e-03,  1.9820e-03,  4.0976e-02,  1.8464e-03,  2.9901e-02,\n",
      "         4.5337e-03,  1.8828e-02,  2.2986e-03,  3.0467e-02,  1.0978e-02,\n",
      "         1.5754e-03,  7.2249e-04,  4.4721e-03,  5.5425e-02, -2.0329e-03,\n",
      "         1.5432e-02,  2.1553e-02,  2.2438e-02, -6.8891e-02,  2.0837e-02,\n",
      "         1.8951e-03, -1.7890e-04, -1.9755e-01,  2.0842e-02,  2.1043e-02,\n",
      "         2.9991e-02, -1.3452e-03,  5.9404e-03,  2.6308e-02,  2.2133e-02,\n",
      "        -1.5321e-01,  2.3584e-05,  1.8798e-03,  6.9556e-03,  4.4604e-02,\n",
      "        -1.3807e-02,  1.1529e-02,  3.9524e-03,  2.4145e-02,  7.2678e-04,\n",
      "         1.7244e-02,  1.2666e-02,  1.0554e-02,  1.1710e-03,  8.7465e-03,\n",
      "         7.9939e-02,  7.2943e-03,  2.4885e-02,  4.8523e-02,  4.0815e-02,\n",
      "         6.0305e-03,  2.4738e-02,  3.0834e-03, -7.5843e-05, -1.2068e-01,\n",
      "         2.6100e-02,  4.0245e-02,  4.9805e-02, -4.4197e-04,  1.5283e-02,\n",
      "         5.1380e-02,  4.1985e-02, -9.2120e-02, -2.2712e-05,  7.3731e-03,\n",
      "         3.2098e-03,  3.4615e-02,  1.1658e-02,  3.4335e-02,  4.8010e-03,\n",
      "         2.2961e-02,  9.3053e-04,  3.3076e-02,  1.2216e-02,  8.2564e-03],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 7.2990e-03,  1.9301e-02,  1.0722e-01, -1.4494e-02,  6.4323e-02,\n",
      "         1.0933e-01,  6.8484e-02, -1.1291e-01,  5.0043e-02,  1.3018e-02,\n",
      "         1.2985e-04, -5.7350e-01,  6.8704e-02,  1.4472e-01,  7.4423e-02,\n",
      "         2.1470e-03,  3.6417e-02,  1.0156e-01,  7.1448e-02, -4.4168e-01,\n",
      "        -2.6091e-04,  2.3811e-02,  1.2181e-02,  1.2636e-01,  1.5694e-02,\n",
      "         1.4216e-02,  1.7863e-02,  5.2105e-02, -1.0217e-02,  6.0675e-02,\n",
      "         3.8524e-02,  8.9440e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-9.2541e-04, -4.2068e-03, -5.4644e-02, -5.7190e-04, -1.3491e-02,\n",
      "         -2.3220e-02, -1.9788e-02,  2.2154e-02, -1.0106e-02, -2.2179e-03,\n",
      "          3.6811e-06,  9.1631e-02, -1.7218e-02, -3.0928e-02, -2.3304e-02,\n",
      "         -9.6544e-05, -9.7861e-03, -2.8072e-02, -2.1430e-02,  6.7499e-02,\n",
      "         -1.2027e-05, -4.2267e-03, -2.5443e-03, -3.2211e-02, -1.3573e-03,\n",
      "         -1.2060e-02, -2.8546e-03, -1.6212e-02,  8.2915e-04, -1.5265e-02,\n",
      "         -8.4910e-03, -3.2629e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9034e-41, -2.5577e-40, -6.2358e-42, -1.1177e-41,  1.2586e-40,\n",
      "          1.1627e-40, -1.4817e-41, -1.3324e-41,  5.9639e-42, -1.4520e-41,\n",
      "         -1.0775e-41, -2.4342e-41, -4.9522e-42, -9.6676e-42, -5.7593e-43,\n",
      "         -1.3982e-41, -2.1161e-41, -2.7596e-41, -2.1636e-41, -2.6160e-40,\n",
      "         -1.5638e-41,  9.9922e-41, -9.9212e-43, -7.0247e-42,  1.6886e-42,\n",
      "         -1.1571e-41,  1.1589e-41,  8.0715e-42,  2.1164e-41, -1.6489e-41],\n",
      "        [ 1.4576e-41, -7.1228e-42, -5.6290e-42,  2.3606e-41,  2.6658e-40,\n",
      "         -9.0132e-42,  6.4109e-42,  3.9376e-42,  1.5739e-40,  1.6118e-41,\n",
      "          2.0863e-41,  9.0594e-42, -6.7991e-42,  1.8982e-41,  4.1689e-42,\n",
      "          3.6994e-42, -2.8355e-41, -1.4571e-41, -7.9902e-42,  1.2872e-41,\n",
      "          1.0909e-41, -1.6621e-41,  4.4547e-42, -7.0289e-42, -1.6950e-41,\n",
      "          6.1167e-42, -4.4057e-42, -1.2919e-41,  3.0969e-43,  8.2691e-42],\n",
      "        [-1.8808e-40, -5.4454e-42,  2.6400e-42,  2.0215e-41,  9.7348e-42,\n",
      "         -2.6625e-41, -2.3114e-41,  9.2794e-42, -4.0988e-42,  8.7791e-42,\n",
      "          8.7441e-43, -8.5984e-42, -8.1696e-42,  1.1412e-41,  9.0075e-42,\n",
      "         -1.4323e-41, -1.0765e-41, -1.6087e-42,  8.0953e-41,  1.1618e-41,\n",
      "          1.1553e-40, -2.2749e-41, -8.0995e-42,  1.0264e-40, -1.8580e-41,\n",
      "          3.9489e-42,  1.2408e-41, -5.7369e-42,  1.2619e-41,  1.9555e-41]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.3335e-41,  2.0766e-41,  1.9062e-41],\n",
      "        [-1.5203e-41, -1.2711e-41,  6.8986e-42],\n",
      "        [-5.4281e-41,  7.9846e-42, -2.3271e-41],\n",
      "        ...,\n",
      "        [ 2.3856e-41,  1.3607e-41, -1.6834e-41],\n",
      "        [ 1.4531e-42, -1.3380e-41, -1.2707e-41],\n",
      "        [ 1.4321e-42,  2.3651e-41, -4.2768e-42]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-5.1153e-06,  4.2218e-05,  1.5463e-04,  ..., -1.5295e-04,\n",
      "        -2.5675e-03,  3.8837e-04], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0025,  0.0183,  0.0754, -0.0473, -0.0073,  0.1361, -0.0022, -0.0098,\n",
      "         0.0202,  0.3415, -0.0382, -0.0004, -0.0041, -0.0523, -0.3708,  0.0033,\n",
      "         0.2386, -0.0010,  0.0374, -0.0381,  0.0049,  0.0745,  0.1249, -0.0020,\n",
      "        -0.0424,  0.1488,  0.1512,  0.0079, -0.0009,  0.0038,  0.0614, -0.0111],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 6.4119e-05, -5.0464e-04, -2.2102e-03,  1.2993e-03,  2.0455e-04,\n",
      "         -3.9265e-03,  6.2862e-05,  2.5876e-04, -5.4703e-04, -9.8430e-03,\n",
      "          1.0722e-03,  1.0887e-05,  1.1317e-04,  1.5029e-03,  1.0505e-02,\n",
      "         -8.9413e-05, -6.8846e-03,  3.0865e-05, -1.0731e-03,  1.0513e-03,\n",
      "         -1.3525e-04, -2.1130e-03, -3.5807e-03,  5.4649e-05,  1.1467e-03,\n",
      "         -4.2441e-03, -4.3483e-03, -2.1441e-04,  2.4197e-05, -1.0685e-04,\n",
      "         -1.7462e-03,  3.0503e-04]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.2685e-33, -9.2416e-42, -2.9718e-23,  ..., -2.6919e-42,\n",
      "         -1.1599e-41,  2.2314e-41],\n",
      "        [ 5.5512e-04, -1.1515e-03, -7.2480e-03,  ..., -1.6183e-04,\n",
      "         -1.8826e-03,  3.4363e-04],\n",
      "        [-5.0605e-16, -2.4191e-25,  8.3798e-43,  ..., -1.4730e-41,\n",
      "         -1.9030e-41,  1.3708e-41],\n",
      "        ...,\n",
      "        [ 1.8710e-41,  1.4914e-41, -4.1170e-42,  ..., -2.5065e-41,\n",
      "          1.1432e-41,  5.3474e-42],\n",
      "        [ 4.1538e-04, -1.6937e-03, -1.4865e-02,  ...,  1.5348e-05,\n",
      "          3.2056e-04,  2.9557e-05],\n",
      "        [-4.1413e-05, -1.1838e-03, -1.3215e-09,  ..., -7.2839e-42,\n",
      "         -1.4924e-11,  2.2156e-41]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-9.0166e-08,  9.7446e-02, -1.1728e-08, -4.0243e-02, -2.2229e-04,\n",
      "        -1.4656e-14,  9.8435e-02, -1.5237e-02, -1.1301e-01, -7.6813e-03,\n",
      "         8.0394e-02, -2.5363e-04, -2.0470e-01, -7.7330e-06, -2.6658e-05,\n",
      "         2.6166e-12,  3.0157e-02, -1.0203e-03, -5.4346e-03, -8.7522e-04,\n",
      "        -3.7740e-37, -5.5681e-08, -3.8520e-05, -5.7861e-04, -3.6774e-02,\n",
      "        -1.8954e-06,  5.6581e-02, -1.5172e-07, -7.4618e-05, -3.1982e-22,\n",
      "         6.5570e-02, -5.9234e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 7.2559e-42,  2.6105e-01,  4.6446e-08,  1.7429e-12,  1.2979e-07,\n",
      "         3.1613e-42,  2.9309e-01,  2.2040e-01,  1.3018e-01, -2.0013e-41,\n",
      "         2.6894e-01,  1.4461e-42,  2.3681e-07,  1.3527e-15,  2.5072e-17,\n",
      "         1.0785e-06,  2.8533e-01,  2.9959e-03, -9.1724e-02,  2.6204e-14,\n",
      "         1.6673e-41,  1.9319e-10,  1.5775e-04,  3.1901e-03, -1.5248e-01,\n",
      "         1.3526e-11,  2.6977e-01,  3.4689e-13,  2.1946e-41,  8.4877e-42,\n",
      "         2.8578e-01,  2.8378e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.4908e-03,  1.3009e-01,  3.3465e-07,  1.5298e-04, -8.8304e-10,\n",
      "         8.9060e-04,  6.9783e-02,  1.4374e-02,  8.2861e-03,  6.8560e-05,\n",
      "        -1.0882e-01,  1.5117e-04,  7.2762e-05,  3.1999e-04,  1.7520e-06,\n",
      "        -4.7047e-08, -8.1620e-02,  1.2953e-06, -4.6579e-03, -3.3099e-04,\n",
      "        -1.6894e-03, -1.1368e-03,  1.0073e-02, -3.1623e-09, -1.6666e-02,\n",
      "         2.9214e-07,  1.1427e-01,  1.2346e-03, -9.2498e-10,  1.6348e-03,\n",
      "         8.6493e-02, -3.7318e-05], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 8.0519e-42,  3.2776e-42, -2.2531e-41,  ...,  9.6549e-42,\n",
      "         -1.3555e-41,  3.7134e-43],\n",
      "        [-3.0359e-03,  1.8046e-02, -1.0561e-07,  ..., -9.1047e-04,\n",
      "          1.5715e-02,  1.3180e-05],\n",
      "        [ 1.5021e-41,  9.6406e-35,  2.5830e-38,  ..., -2.5251e-42,\n",
      "         -1.9660e-42, -1.6241e-42],\n",
      "        ...,\n",
      "        [-1.3354e-41, -1.6540e-41, -2.2908e-41,  ..., -1.9636e-41,\n",
      "         -2.2328e-41,  1.3422e-41],\n",
      "        [ 1.4424e-41,  5.5786e-42,  2.7160e-41,  ...,  7.9398e-42,\n",
      "          2.4074e-42, -2.3484e-41],\n",
      "        [ 4.5668e-42, -1.6520e-41, -1.7473e-41,  ..., -1.0378e-41,\n",
      "         -6.6029e-42, -2.4556e-41]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.2561e-41,  2.7831e-02,  1.2654e-41,  5.9051e-42, -3.3211e-43,\n",
      "         2.0299e-41, -6.3871e-42, -1.2749e-35, -3.3492e-41,  3.7331e-42,\n",
      "         1.0078e-41, -3.9510e-41,  6.1195e-42, -1.4897e-41, -1.9398e-41,\n",
      "         2.5732e-38,  2.4228e-42,  5.7443e-02,  1.2416e-41,  2.1942e-25,\n",
      "         1.8287e-41, -1.1052e-41,  6.9631e-42,  2.7997e-41, -6.8923e-03,\n",
      "        -9.4293e-42,  4.8198e-02,  1.0318e-41, -9.8287e-42,  2.2281e-43,\n",
      "         1.8891e-41,  1.4325e-41, -1.0627e-41,  2.3709e-41,  1.0637e-19,\n",
      "         5.3125e-02,  7.8473e-42,  1.7803e-41, -8.7609e-42,  2.3237e-20,\n",
      "        -2.1216e-42,  2.9479e-41,  5.9583e-42,  2.8909e-42, -1.4758e-41,\n",
      "         5.5517e-09,  6.0287e-02, -5.6215e-20,  2.6555e-42, -1.0905e-41,\n",
      "        -2.9649e-41, -1.6633e-41,  6.9281e-02,  9.8315e-42,  2.0876e-15,\n",
      "        -4.2019e-41,  3.0114e-42, -8.3770e-42, -2.1904e-41, -4.5052e-42,\n",
      "        -6.6408e-42,  2.2531e-41,  6.6126e-02, -3.8466e-42, -1.1931e-41,\n",
      "        -2.8977e-41, -2.4902e-41,  1.9524e-41, -2.3475e-41,  4.2437e-02,\n",
      "         1.1521e-25, -2.0850e-41, -4.7813e-07, -6.9813e-42,  1.9192e-41,\n",
      "        -9.3901e-42,  2.3503e-41,  4.9834e-02,  1.7064e-41,  3.2544e-41,\n",
      "         1.9805e-41,  3.7903e-02,  3.6964e-02, -7.3764e-42, -1.0552e-42,\n",
      "         8.9277e-20, -2.3442e-41, -4.5038e-42,  1.0089e-43,  4.6243e-42,\n",
      "        -2.6737e-42,  1.3158e-41,  5.0129e-02,  4.1293e-13, -9.9997e-42,\n",
      "         2.5320e-41, -1.6116e-41,  4.1156e-42,  7.1566e-02, -1.8356e-41,\n",
      "         5.1324e-14,  1.5400e-42,  2.4223e-27,  2.7372e-41,  6.5165e-02,\n",
      "        -2.5633e-41,  6.3006e-02,  5.5048e-02,  1.0466e-41, -1.3597e-41,\n",
      "        -7.5110e-43, -2.1720e-42, -7.6679e-42, -6.4306e-42, -2.1493e-41,\n",
      "         3.1597e-25, -1.2589e-41, -1.8613e-41,  1.1440e-41,  3.6150e-02,\n",
      "        -4.7910e-42,  1.2777e-19,  5.5029e-42,  1.9666e-41,  5.7039e-17,\n",
      "        -2.2739e-41,  8.0909e-30, -2.5083e-42,  3.3869e-42, -2.0441e-41,\n",
      "         1.8279e-41,  2.0491e-41, -2.2110e-41,  9.0524e-43,  6.1699e-42,\n",
      "         1.4407e-41, -1.1877e-41, -2.1984e-41,  1.3751e-41, -2.2163e-41,\n",
      "        -2.6335e-41,  2.3327e-41,  3.4766e-42,  7.3134e-42,  2.6478e-41,\n",
      "        -3.2482e-42,  1.8982e-41,  7.8720e-02,  3.8452e-42,  4.3468e-42,\n",
      "         7.1452e-42,  2.6658e-41, -4.5262e-43,  1.7606e-40,  1.7867e-41,\n",
      "         2.0601e-12, -7.8879e-42,  7.4689e-43,  2.7678e-41,  1.3118e-41,\n",
      "        -3.3043e-42,  1.0227e-41,  1.0059e-03,  4.1086e-42,  5.0544e-06,\n",
      "         2.6716e-06,  1.0825e-41,  2.1860e-42,  2.2984e-41, -1.1629e-41,\n",
      "         2.0382e-41, -1.4588e-42, -3.6569e-32,  2.8274e-41, -1.1052e-41,\n",
      "         1.6795e-41, -6.9266e-42, -3.0137e-37,  1.3224e-41, -1.2193e-41,\n",
      "         1.8535e-41,  4.9554e-02, -4.0736e-42, -9.2205e-42, -1.4905e-37,\n",
      "        -2.6022e-42,  1.6961e-41,  9.1477e-42,  5.3025e-42, -2.1334e-25,\n",
      "        -1.6199e-41,  2.4550e-15,  5.6661e-37,  7.0233e-42, -1.8527e-41,\n",
      "        -1.2700e-41, -4.4982e-43,  2.0236e-41,  6.9084e-42, -3.4056e-27,\n",
      "        -2.5775e-41, -2.6443e-42,  2.9199e-41,  8.2293e-25,  1.5631e-10,\n",
      "         3.4822e-42,  1.2359e-42, -1.5553e-41, -2.7540e-41,  7.5250e-43,\n",
      "        -1.1709e-41,  5.9062e-02, -6.1293e-42, -2.2987e-41, -2.1678e-42,\n",
      "         5.4384e-42,  1.9390e-41,  2.8341e-41,  2.1132e-41, -2.2506e-41,\n",
      "        -1.1868e-41, -9.3747e-42, -4.6873e-42,  1.7003e-41,  1.9345e-41,\n",
      "         1.7667e-37, -1.7680e-41, -1.5326e-41,  6.9687e-42,  3.0325e-02,\n",
      "        -1.9471e-41,  2.8651e-41,  7.1099e-02, -1.6237e-41,  3.0882e-20,\n",
      "         7.2349e-42,  3.7723e-42,  4.6500e-02, -1.4344e-41,  1.6586e-41,\n",
      "         1.6526e-41,  2.5974e-41,  3.4962e-42,  7.2603e-02,  8.8464e-42,\n",
      "         1.5868e-41,  1.9935e-41, -2.3037e-41,  3.7413e-02, -2.0624e-41,\n",
      "        -6.4754e-42, -4.0427e-42,  2.8330e-41, -1.4391e-42,  8.5816e-42,\n",
      "         1.7536e-41,  5.1848e-42,  2.0203e-41,  6.4495e-02, -1.0155e-41,\n",
      "         5.2812e-02,  4.7843e-02,  1.4614e-41, -1.3387e-41,  1.8786e-41,\n",
      "        -1.5348e-41, -2.0753e-42,  1.5047e-21,  4.0540e-42, -6.1419e-42,\n",
      "         2.7166e-41, -1.3069e-41,  8.7231e-42,  2.2694e-41,  1.0619e-41,\n",
      "        -1.2099e-41, -1.9704e-33, -5.1428e-43,  2.2348e-41, -2.2541e-41,\n",
      "        -1.5088e-41, -2.4041e-33, -7.0710e-42,  2.1845e-41,  6.2438e-38,\n",
      "        -1.0297e-41, -1.0989e-41,  1.7628e-42,  5.9289e-42, -7.7198e-42,\n",
      "        -5.9289e-37, -6.8327e-42,  8.0041e-36,  2.0124e-02,  6.7543e-43,\n",
      "        -7.2405e-42,  2.0097e-41,  1.4904e-41,  2.3342e-13, -1.6322e-41,\n",
      "        -8.6754e-42,  1.0721e-41,  5.0307e-43, -2.3381e-41,  2.3941e-41,\n",
      "         1.5166e-41,  2.1567e-41,  3.1214e-38, -2.5839e-41, -3.3631e-42,\n",
      "        -3.0709e-41, -1.5760e-41, -4.0778e-42, -1.6803e-41, -1.2416e-41,\n",
      "         2.4970e-41,  1.6717e-42, -1.1458e-41,  7.7048e-12,  4.0841e-04,\n",
      "        -7.1508e-42,  3.9797e-43,  2.1790e-41, -1.3794e-41,  4.7053e-02,\n",
      "         5.6444e-42,  1.0583e-41,  3.7934e-02,  6.3475e-02,  1.6174e-04,\n",
      "         5.6904e-02, -3.9334e-42, -2.3749e-41,  6.5609e-42,  1.0374e-41,\n",
      "        -1.5875e-41, -5.3375e-42, -2.5949e-41, -1.2008e-41, -1.6698e-41,\n",
      "        -2.2688e-41, -4.5052e-42,  3.6434e-42, -2.1737e-41, -2.5994e-42,\n",
      "        -1.2455e-41,  6.2777e-28, -1.4274e-41,  5.7022e-25,  1.2135e-42,\n",
      "         5.3743e-02, -2.3542e-41, -2.7543e-41,  8.0799e-42,  1.3880e-41,\n",
      "         1.8861e-42,  1.7118e-13, -8.0210e-42, -9.6788e-42,  1.5182e-41,\n",
      "         2.7097e-41, -8.9417e-42, -2.2564e-41, -1.2849e-41,  1.6248e-02,\n",
      "        -3.7162e-42,  5.7573e-02,  9.6353e-42,  1.7052e-41, -6.8383e-42,\n",
      "         1.5519e-41, -1.4932e-41,  9.7783e-42, -1.5875e-28, -1.0906e-41,\n",
      "        -2.7557e-41, -2.1670e-41, -3.3097e-41, -3.0148e-41,  2.6392e-41,\n",
      "         6.6323e-42, -3.4822e-41,  2.4957e-41, -1.2137e-41, -1.9353e-41,\n",
      "         2.7618e-41, -1.1775e-41,  1.9715e-41,  6.4670e-42, -7.8515e-42,\n",
      "         4.9508e-42,  1.0608e-41, -1.4031e-41,  1.8974e-41, -3.7373e-42,\n",
      "         8.4568e-42,  8.3784e-42,  1.3782e-23, -2.1052e-41,  1.6905e-41,\n",
      "        -9.3355e-42,  1.9736e-41,  6.6197e-42,  4.5893e-42, -2.7903e-41,\n",
      "        -1.9938e-41,  6.7262e-44, -1.5420e-41,  3.7975e-42,  3.1923e-37,\n",
      "         2.0067e-41, -4.3122e-34,  2.5794e-41, -1.1502e-41,  1.8178e-41,\n",
      "         1.6702e-41, -2.9497e-42,  2.8344e-41,  7.1466e-44, -1.1443e-41,\n",
      "        -7.4795e-17, -1.7291e-41,  4.7337e-02,  5.3282e-02,  1.5205e-41,\n",
      "         9.1084e-44,  4.5013e-02,  2.4282e-41,  1.5079e-41,  1.5479e-41,\n",
      "         1.2937e-41,  3.5970e-02,  1.4744e-41,  2.0310e-41, -2.1608e-42,\n",
      "        -2.3760e-41,  1.8786e-14, -9.0092e-41,  2.4534e-02,  1.9828e-42,\n",
      "         2.0458e-41, -6.5216e-42,  1.5462e-41, -1.2218e-41, -3.3726e-41,\n",
      "         1.1296e-41, -1.6228e-41, -6.8580e-40, -2.1664e-42, -2.5293e-41,\n",
      "        -1.5839e-41, -1.2121e-42,  9.9927e-42, -1.1805e-41, -1.6713e-41,\n",
      "         1.5220e-41,  2.6485e-14, -2.6640e-41, -1.5587e-41,  3.1479e-41,\n",
      "         4.9535e-02, -1.4732e-41,  2.4825e-41,  1.1474e-41,  7.2495e-02,\n",
      "         4.1548e-02,  3.2971e-24,  3.4534e-41,  1.2180e-41,  2.9960e-42,\n",
      "        -5.6542e-42, -1.0299e-31,  7.1703e-02,  1.4924e-41,  3.4808e-42,\n",
      "        -1.6373e-41,  6.8355e-14, -4.2557e-42,  4.7938e-02,  1.0833e-41,\n",
      "        -2.1310e-41,  1.2777e-41, -1.6311e-42, -2.3980e-41, -4.0554e-42,\n",
      "        -2.5003e-41,  3.5121e-11,  2.2213e-04,  1.8772e-41, -1.0647e-41,\n",
      "        -1.9104e-41, -1.7627e-41,  6.9042e-42,  5.3978e-42, -1.6923e-41,\n",
      "         1.7163e-41,  5.4511e-42,  6.2457e-02,  2.8158e-41,  1.1470e-41,\n",
      "        -1.0845e-41, -1.6552e-41, -5.9934e-42,  6.3530e-02, -2.3588e-41,\n",
      "        -2.2617e-42, -1.7030e-41,  3.8736e-02, -6.7388e-42,  3.3708e-41,\n",
      "         2.1374e-41,  1.8667e-41], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4433e-43,  1.2803e-01, -3.5636e-41, -1.2794e-41,  1.2201e-41,\n",
      "         7.1116e-42, -2.8435e-41,  1.2420e-41, -1.0290e-41,  8.0126e-42,\n",
      "        -1.9954e-42,  1.5989e-41, -2.1378e-41,  2.4228e-42,  1.6754e-41,\n",
      "        -2.5872e-41, -6.3773e-42,  3.1285e-01,  2.2939e-42,  1.6118e-41,\n",
      "         9.2079e-42, -1.1639e-41,  1.9782e-41,  1.0979e-41,  1.4447e-08,\n",
      "        -9.8792e-43,  4.0319e-01, -2.7269e-42, -1.9758e-42,  1.9807e-41,\n",
      "        -1.7803e-41,  2.0535e-41,  1.9365e-41,  2.5369e-41, -1.3574e-41,\n",
      "         3.3554e-01,  9.1042e-42, -1.7530e-41, -1.0260e-41, -1.7970e-41,\n",
      "        -1.7675e-41,  2.1679e-41, -2.7784e-41, -2.2813e-41,  5.1554e-42,\n",
      "         1.2585e-19,  2.9901e-01, -9.4055e-42,  5.2689e-42,  1.0620e-41,\n",
      "         1.1465e-41, -1.8414e-41,  4.0935e-01,  2.3043e-41, -2.6777e-41,\n",
      "         2.0896e-41,  2.2950e-41,  8.6236e-42, -1.7771e-41, -3.7148e-42,\n",
      "        -1.9862e-41,  1.4410e-41,  2.9124e-01,  2.0721e-41,  1.1366e-41,\n",
      "         4.3314e-42, -1.1269e-41,  1.4338e-41,  2.0488e-41,  2.8575e-01,\n",
      "         2.1218e-41,  1.2865e-41,  1.6513e-27, -2.4563e-41,  1.0433e-41,\n",
      "        -9.3340e-42,  3.6966e-42,  4.1066e-01,  1.8661e-41,  2.5630e-42,\n",
      "         1.1161e-41,  1.4941e-01,  4.4614e-01, -1.1613e-41,  1.0653e-41,\n",
      "        -1.1038e-41, -1.6746e-42, -1.8471e-41,  1.6610e-41,  1.6624e-41,\n",
      "         2.4530e-41, -8.7399e-42,  3.1426e-01, -1.0949e-33, -1.3136e-41,\n",
      "        -1.3588e-41, -2.6012e-41, -6.0985e-42,  2.8811e-01,  8.8310e-42,\n",
      "         7.1278e-37,  1.3275e-41,  2.8068e-42, -1.0210e-41,  3.0217e-01,\n",
      "        -1.3492e-41,  3.6225e-01,  4.1368e-01,  7.3764e-42,  2.6583e-42,\n",
      "         2.1630e-41,  6.5917e-42,  1.3708e-41,  5.7790e-42, -2.7129e-42,\n",
      "        -3.3734e-38,  5.7818e-42,  1.5589e-41,  2.6629e-41,  2.6390e-01,\n",
      "         2.5914e-41,  2.0264e-41, -4.9382e-42,  1.2354e-41,  7.4266e-37,\n",
      "         2.0243e-41,  7.9636e-42, -1.8322e-41, -1.5477e-41, -7.6875e-42,\n",
      "        -5.7383e-42, -7.9860e-42, -1.3216e-41,  6.4824e-42,  1.5596e-42,\n",
      "        -1.3650e-41,  4.8989e-42, -1.0374e-41,  1.1482e-41, -2.4830e-41,\n",
      "        -8.4919e-42, -1.5051e-41, -2.4419e-41, -3.2363e-41, -1.9121e-41,\n",
      "        -7.1046e-43,  3.2790e-42,  3.1868e-01,  2.2421e-43, -1.0074e-41,\n",
      "        -4.1591e-42, -1.6591e-42, -1.5222e-41,  1.2472e-43,  1.6995e-41,\n",
      "        -2.3266e-33,  6.8481e-42, -2.8864e-41,  6.0606e-42,  2.5986e-41,\n",
      "         1.1046e-41,  9.0720e-42,  1.4147e-03,  2.0019e-41,  3.2682e-16,\n",
      "         5.2347e-15,  2.1087e-41, -2.6965e-41, -5.4272e-42,  2.0785e-41,\n",
      "        -4.7798e-42,  1.4953e-41, -2.8641e-41, -3.4010e-42, -3.2776e-42,\n",
      "         2.2452e-41,  1.1313e-41,  1.1964e-41,  4.9003e-42,  2.4513e-41,\n",
      "        -2.1801e-41,  2.7582e-01,  6.4642e-42,  3.7737e-42, -2.1577e-41,\n",
      "         8.8702e-43,  1.0136e-41,  1.9861e-41,  5.7439e-42,  4.9077e-39,\n",
      "        -1.7697e-41,  1.2484e-33, -3.2646e-41,  1.5739e-41, -1.6900e-42,\n",
      "         1.1520e-41,  2.2522e-41,  1.7267e-41,  1.0889e-41, -2.2810e-41,\n",
      "        -8.7945e-42, -6.5399e-42,  8.0883e-42,  1.9886e-41,  1.4472e-24,\n",
      "        -1.5060e-41, -7.3176e-42, -1.6262e-41, -9.1771e-42, -3.3463e-42,\n",
      "        -9.1645e-43,  3.9410e-01, -4.2894e-42, -2.0963e-42,  2.0889e-41,\n",
      "         5.6697e-42, -7.2868e-44,  1.1701e-42, -9.5807e-42,  1.0052e-41,\n",
      "        -9.0664e-43,  1.2372e-41, -2.1942e-41,  2.4311e-41, -1.8077e-42,\n",
      "         1.3741e-41,  2.8013e-41,  2.2529e-41, -1.0742e-41,  4.2772e-01,\n",
      "         2.1932e-41, -1.0307e-41,  3.6456e-01, -7.3820e-42,  1.4346e-41,\n",
      "        -7.4731e-42, -2.6814e-41,  3.8371e-01,  7.3596e-42, -2.0868e-41,\n",
      "         2.6776e-41, -1.2797e-41, -9.5414e-42,  2.8366e-01, -8.3111e-42,\n",
      "        -2.4409e-41, -2.1848e-41,  1.3715e-41,  3.0624e-01,  1.1045e-41,\n",
      "         4.8065e-42, -2.4514e-41,  1.2273e-41, -9.7713e-42, -9.9254e-42,\n",
      "         1.1537e-41,  6.8271e-42, -9.7306e-42,  3.1496e-01, -5.7677e-42,\n",
      "         3.5467e-01,  3.1590e-01,  2.5569e-41,  3.2132e-42, -2.5368e-41,\n",
      "         5.1288e-42, -1.6122e-41, -3.4954e-39, -1.6341e-41, -9.2009e-42,\n",
      "         2.4981e-41,  2.7383e-41, -1.1632e-41, -8.2522e-42, -1.5706e-41,\n",
      "         2.6961e-42, -2.2442e-41, -1.2040e-41,  1.2910e-41, -6.1853e-42,\n",
      "        -9.7236e-42, -1.5107e-41,  1.4681e-41,  6.8243e-42, -1.2204e-41,\n",
      "        -1.2483e-41, -1.7967e-41, -2.1314e-42, -2.2641e-41,  2.9217e-41,\n",
      "        -1.3629e-41,  1.2815e-41, -8.7903e-42,  3.6881e-01, -1.6185e-42,\n",
      "         2.8376e-42, -2.0268e-41, -2.4668e-41, -1.0846e-38,  5.7593e-43,\n",
      "         1.7345e-41,  1.4753e-41, -9.6143e-42, -4.3286e-42, -1.5182e-41,\n",
      "        -2.6386e-42, -9.1785e-42,  3.4710e-42, -9.6283e-42,  9.0594e-42,\n",
      "         9.6774e-42, -6.6940e-42,  7.8375e-42, -1.7387e-41,  1.7425e-41,\n",
      "        -1.9999e-41, -2.4017e-41,  2.2889e-41, -1.5130e-34, -9.3240e-05,\n",
      "         3.9783e-42,  6.6562e-43,  2.4172e-41,  4.1969e-42,  2.9660e-01,\n",
      "         4.1240e-42,  3.2384e-42,  3.3982e-01,  3.6299e-01,  8.9912e-05,\n",
      "         4.2240e-01,  2.1349e-41, -1.5605e-41,  2.0811e-41, -1.8933e-41,\n",
      "         1.0706e-41,  2.7240e-41,  1.7679e-41,  2.4612e-41, -4.8653e-42,\n",
      "         1.3071e-41, -2.8812e-41,  1.6504e-41,  2.2041e-41, -4.2403e-42,\n",
      "         2.6344e-42, -1.4498e-41, -2.0593e-41, -2.1373e-41, -2.4943e-43,\n",
      "         1.7093e-01, -2.6246e-42,  1.9573e-41,  1.7455e-41,  1.7623e-41,\n",
      "         2.1221e-41, -1.8862e-28, -4.9059e-42,  9.7516e-42,  5.2577e-42,\n",
      "        -2.8022e-41,  1.2146e-41, -1.2139e-41,  9.6984e-42,  2.7584e-01,\n",
      "         5.6024e-42,  4.4162e-01, -1.2763e-41, -4.4071e-42, -2.5505e-41,\n",
      "        -1.8877e-41,  7.6861e-42, -4.2361e-42,  4.5782e-41, -2.7510e-41,\n",
      "         8.8688e-42, -3.6938e-42,  3.0646e-42, -2.6225e-41, -1.4232e-41,\n",
      "         9.2864e-42, -1.2654e-42,  2.6213e-41,  3.1109e-43,  5.3530e-43,\n",
      "         1.2092e-41,  3.1123e-42,  2.0586e-41,  6.2610e-42, -1.1126e-42,\n",
      "        -6.8636e-42, -2.2226e-41, -2.1793e-41, -1.9852e-41, -2.2027e-41,\n",
      "         1.8707e-42, -2.4999e-42,  2.3945e-40, -2.8615e-42,  2.6127e-41,\n",
      "         1.3443e-41, -2.6513e-42,  1.3202e-41,  1.6779e-41,  2.2718e-41,\n",
      "        -1.6109e-41,  5.6598e-42,  1.2061e-41,  5.5309e-42,  2.3962e-42,\n",
      "        -2.0043e-41, -2.4341e-42, -2.7412e-41, -1.3345e-41, -5.6921e-42,\n",
      "         1.6429e-41, -4.9326e-42,  7.3848e-42,  2.0713e-41, -7.0752e-42,\n",
      "        -2.6842e-41, -2.3103e-41,  3.8770e-01,  3.7457e-01, -1.1977e-41,\n",
      "        -1.1331e-41,  2.9786e-01, -2.7952e-41, -2.0879e-42,  1.7676e-41,\n",
      "         2.3177e-41,  4.0907e-01,  1.7826e-41, -1.8904e-41, -1.9610e-41,\n",
      "        -4.5262e-42,  4.5763e-28, -1.5693e-41,  8.4811e-02,  1.3172e-42,\n",
      "        -2.4771e-41, -2.7435e-41, -1.2839e-41,  1.2444e-42,  1.7383e-41,\n",
      "        -1.3922e-41,  1.4379e-41,  1.0089e-43,  1.0763e-41,  1.2764e-41,\n",
      "         1.0103e-41,  1.8018e-41, -5.4511e-43,  1.6921e-41, -2.0809e-42,\n",
      "        -2.2258e-41, -2.9364e-34, -8.9991e-42, -2.4517e-41,  2.7820e-41,\n",
      "         2.6025e-01,  7.8571e-42,  2.3878e-42,  2.8816e-41,  2.8985e-01,\n",
      "         3.1441e-01, -5.2741e-34,  4.1002e-42,  2.4992e-41,  1.8200e-41,\n",
      "        -4.7112e-42,  4.8359e-42,  3.3416e-01, -2.2737e-41, -1.2259e-41,\n",
      "        -1.9646e-41,  1.8308e-36, -4.4421e-43,  3.0331e-01,  2.5619e-41,\n",
      "         5.6332e-43, -1.9451e-41, -1.8906e-41,  2.7223e-41,  2.2747e-41,\n",
      "         1.3591e-41, -4.5761e-37,  1.0589e-04, -6.1769e-42, -2.6625e-41,\n",
      "        -1.3493e-41,  1.6790e-41,  1.0553e-41,  1.3317e-41, -2.0585e-42,\n",
      "        -1.4921e-41, -1.4361e-41,  3.3358e-01, -4.2459e-43, -9.9142e-42,\n",
      "         2.0245e-41, -1.6178e-41, -6.2414e-42,  2.7724e-01, -4.9326e-42,\n",
      "        -1.7956e-41, -4.3328e-42,  3.9928e-01, -2.3388e-42, -1.8664e-41,\n",
      "         5.1904e-42,  1.6115e-42], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 8.3379e-22,  6.5100e-03, -1.9869e-24,  4.2755e-27, -3.8004e-21,\n",
      "        -4.4206e-25,  6.9793e-26, -5.2094e-23,  2.4352e-20,  2.7440e-26,\n",
      "        -4.6125e-29, -1.7673e-15, -1.0682e-22, -6.4258e-24, -1.1302e-28,\n",
      "         3.9356e-18, -1.4725e-22,  1.2652e-02, -5.0170e-22,  4.5625e-22,\n",
      "        -3.8058e-25, -4.0732e-35,  3.6506e-36, -1.6945e-26,  2.9723e-04,\n",
      "         1.0801e-41, -1.9322e-02,  1.1803e-24,  1.9510e-24, -3.8266e-37,\n",
      "        -8.9473e-18,  2.9716e-24, -1.1145e-24,  1.0455e-21,  2.3773e-20,\n",
      "        -3.1661e-03,  1.1689e-21,  2.7914e-42, -2.2554e-21,  1.2245e-19,\n",
      "         4.2237e-25,  7.1412e-26, -1.3321e-18,  9.2205e-42, -1.8453e-24,\n",
      "         3.6032e-08,  3.5178e-03, -2.3128e-35,  9.5925e-39,  1.3352e-20,\n",
      "         2.7089e-26, -2.4243e-30,  4.6092e-02, -1.0508e-25,  1.0336e-18,\n",
      "        -2.6604e-17,  6.2541e-37,  2.1080e-24, -1.3987e-27,  6.7039e-39,\n",
      "         4.4841e-37, -7.7321e-31,  4.2125e-02, -1.3100e-24,  7.0182e-18,\n",
      "         6.6420e-16,  4.3241e-25,  5.5188e-32,  3.5780e-38,  1.6203e-02,\n",
      "         1.1474e-19,  3.9996e-32,  6.9080e-10, -9.5392e-29,  1.4013e-45,\n",
      "         9.5451e-36,  1.4175e-20,  4.2808e-02, -3.8648e-42,  1.3570e-21,\n",
      "        -4.2545e-23,  2.7753e-02, -4.1566e-02, -1.3552e-32,  1.2542e-42,\n",
      "        -4.9882e-17,  1.2291e-39, -1.3845e-25,  2.3099e-22, -3.2095e-19,\n",
      "        -6.7732e-22, -6.9573e-20,  3.1493e-02, -4.0721e-13, -9.6272e-33,\n",
      "        -3.0747e-32, -6.6540e-21, -1.9215e-28,  3.9533e-02,  1.3034e-29,\n",
      "         2.4702e-13,  1.0565e-32, -2.3750e-16, -4.1089e-25,  4.0795e-02,\n",
      "        -2.3177e-17,  1.6581e-02,  4.3215e-03,  9.6241e-32,  4.5991e-36,\n",
      "        -5.6645e-38,  5.6238e-22, -1.2743e-31, -7.7976e-22, -1.9663e-23,\n",
      "         1.3254e-10, -3.0668e-28,  1.3745e-19,  1.4512e-28, -2.6965e-03,\n",
      "        -1.0846e-33,  4.7793e-28,  5.8771e-39,  9.6780e-28,  1.8404e-10,\n",
      "         1.8745e-36, -1.3552e-16,  9.6090e-30, -1.2238e-22,  9.2387e-18,\n",
      "         1.9048e-41,  5.4919e-17, -4.3186e-19, -2.5181e-27,  1.4006e-41,\n",
      "         3.3897e-32, -2.1507e-27,  3.8887e-25, -3.3230e-29, -3.1978e-26,\n",
      "        -4.0543e-18, -7.6973e-42,  4.6064e-30, -1.7875e-28, -1.5577e-41,\n",
      "        -4.3868e-31,  1.7014e-30,  7.2096e-02,  1.5890e-20, -5.4517e-34,\n",
      "         6.5992e-22, -3.6842e-23,  1.4038e-40, -2.3805e-17,  7.8856e-24,\n",
      "         1.3440e-11, -9.8013e-16, -4.6570e-16, -9.7986e-26,  3.6282e-22,\n",
      "         1.5801e-21, -8.1760e-23,  9.2133e-04, -1.6888e-28,  5.6975e-06,\n",
      "         2.9097e-07,  3.3015e-27,  5.8519e-36,  4.2998e-23, -9.8415e-30,\n",
      "        -5.5775e-22,  8.6372e-29,  9.1426e-17,  5.1069e-38, -6.2658e-34,\n",
      "        -4.5715e-22, -4.9707e-28,  2.9066e-24,  1.8874e-23, -4.6708e-33,\n",
      "         5.6382e-30,  4.4726e-03, -2.5783e-29, -3.3768e-29,  6.3433e-15,\n",
      "         1.4672e-28, -3.8085e-17, -6.8499e-26,  3.9239e-20,  1.1631e-11,\n",
      "         6.9913e-22,  1.7562e-10,  1.4419e-12,  3.6733e-35,  5.9186e-28,\n",
      "        -8.9771e-34,  2.3743e-27, -7.5938e-18,  4.5427e-22,  1.0925e-19,\n",
      "         6.8566e-42, -3.2548e-20, -1.2550e-24, -1.0577e-14, -9.3007e-10,\n",
      "         5.0807e-23,  1.3536e-19,  1.9987e-33,  2.1232e-26, -6.4472e-24,\n",
      "         5.0386e-28,  1.6965e-02, -3.8635e-20,  2.0609e-25,  1.0640e-41,\n",
      "        -1.0435e-31,  1.8954e-28, -5.3799e-23,  2.3764e-20,  3.1629e-31,\n",
      "         1.6648e-21, -1.4665e-30,  8.7231e-42,  7.8160e-29, -5.4307e-37,\n",
      "         6.1865e-18,  1.3665e-26,  2.0345e-31, -2.6178e-21,  4.1425e-02,\n",
      "         5.0674e-36, -5.1846e-23, -6.7373e-03,  9.7268e-29,  1.0334e-14,\n",
      "        -2.5057e-37,  6.8913e-24,  2.4063e-02,  3.6755e-20, -1.6378e-25,\n",
      "         1.0646e-32,  8.5259e-25,  1.5285e-24,  2.7549e-02,  2.3829e-27,\n",
      "         1.6534e-26, -3.4847e-30, -6.3734e-25,  8.7412e-04, -6.6795e-17,\n",
      "         1.0079e-29, -1.0567e-23, -1.9805e-19,  4.7767e-24, -9.3172e-42,\n",
      "        -1.3955e-29, -4.5310e-29,  4.2166e-30,  4.0324e-02, -9.7848e-36,\n",
      "         5.1971e-02,  1.5047e-02,  3.7426e-22,  6.9170e-23,  1.6854e-32,\n",
      "        -4.7702e-29, -3.0566e-21,  5.9657e-14,  3.0396e-22,  6.6004e-21,\n",
      "        -3.1121e-34,  3.6412e-29,  4.2679e-26,  4.8073e-37,  2.3832e-27,\n",
      "         1.6275e-16, -5.6692e-27,  2.7712e-31,  1.3986e-18, -5.0164e-37,\n",
      "         1.6675e-21, -2.4486e-20,  1.8578e-26, -3.7001e-31, -5.1293e-19,\n",
      "         1.2580e-18,  2.9550e-28,  3.8653e-25, -1.1525e-40, -1.0172e-25,\n",
      "        -6.7977e-29, -1.2662e-21,  1.4439e-17, -1.6985e-03,  2.1036e-21,\n",
      "        -4.8331e-35, -4.1624e-38,  3.0681e-24,  8.1021e-16, -2.2165e-26,\n",
      "         5.9384e-23,  9.2450e-20,  4.0769e-30,  1.3220e-24, -1.5361e-41,\n",
      "        -2.9240e-29,  1.2077e-27,  2.5246e-28, -1.8346e-30, -3.7084e-23,\n",
      "        -7.2691e-40, -3.2907e-32,  4.4026e-21,  2.1567e-21, -7.1292e-22,\n",
      "        -2.6841e-17, -8.0495e-22,  7.6481e-24, -2.1323e-13, -3.6066e-04,\n",
      "        -5.2050e-33,  1.0522e-14, -1.5589e-22, -2.5331e-35,  2.5009e-02,\n",
      "         1.6101e-20,  1.8695e-15,  4.4357e-03,  3.9018e-02, -9.5240e-05,\n",
      "        -5.2355e-03, -8.7532e-25, -6.3560e-28,  3.2376e-22, -1.1812e-28,\n",
      "         1.8890e-41,  3.8854e-29, -1.4497e-27,  1.1927e-21,  1.3659e-31,\n",
      "         2.9939e-37, -5.1641e-24,  1.0129e-29, -4.3738e-18,  8.0032e-20,\n",
      "         3.5437e-20,  1.7972e-15, -1.0159e-28,  6.1664e-38,  1.0827e-31,\n",
      "         2.4909e-02,  2.8783e-42,  2.2337e-28, -2.3318e-30, -2.3256e-38,\n",
      "         3.4297e-18, -4.7675e-08, -1.0553e-32, -4.9541e-21,  2.7713e-23,\n",
      "         2.4362e-29, -1.5624e-42,  6.2632e-34,  9.7514e-31, -4.7816e-02,\n",
      "         6.9958e-20,  2.3735e-03, -3.9500e-26,  3.3952e-23, -1.7171e-22,\n",
      "        -1.1107e-24,  2.1696e-20,  3.3434e-35,  1.6563e-10,  4.0716e-35,\n",
      "         3.4973e-28, -5.9763e-31, -5.1817e-30, -6.0673e-24, -1.5871e-23,\n",
      "         1.3924e-32,  1.0742e-15, -8.5997e-23, -5.6408e-24,  2.0250e-26,\n",
      "         1.7789e-20,  1.3892e-25,  1.4875e-20,  4.5444e-42, -5.3017e-19,\n",
      "         2.4735e-23, -4.1878e-31, -1.6647e-24, -1.7480e-35,  2.4555e-25,\n",
      "        -2.2725e-22, -1.6784e-27, -1.9651e-11, -1.5265e-37,  5.1670e-29,\n",
      "        -4.0539e-24, -1.8413e-31,  5.5573e-33, -1.9522e-22,  2.0114e-19,\n",
      "         1.4594e-28,  3.7728e-39,  3.5742e-23,  1.6548e-24,  6.0374e-22,\n",
      "         1.7906e-28, -5.3771e-31,  2.6453e-39,  6.8567e-34, -1.7338e-16,\n",
      "        -4.9707e-21,  3.3482e-24,  1.8035e-41, -9.0828e-16,  1.7354e-28,\n",
      "         1.5074e-14, -1.7400e-20,  1.4440e-02,  1.2354e-02, -1.2598e-32,\n",
      "         3.0248e-27, -2.5748e-02,  4.3026e-15, -5.6669e-42, -2.9303e-22,\n",
      "        -5.4504e-20,  1.1808e-02,  4.6858e-21, -1.6752e-23, -1.7671e-32,\n",
      "         3.9534e-20,  1.3647e-10, -1.3897e-30,  5.6083e-03, -8.2727e-23,\n",
      "        -7.1035e-17,  8.5677e-25,  1.5437e-35,  3.4093e-28, -1.4416e-16,\n",
      "        -2.1735e-32, -1.4258e-25,  2.7053e-14,  1.9299e-18,  4.1477e-22,\n",
      "         1.0510e-43,  8.0486e-28, -1.4519e-21, -4.9645e-28, -1.4363e-26,\n",
      "         1.8638e-29,  2.3286e-11, -1.9922e-14,  7.6760e-27, -4.0529e-26,\n",
      "         2.8202e-02,  2.6605e-25, -1.8868e-28,  9.0670e-32,  9.6823e-03,\n",
      "         2.0024e-02, -5.7232e-08, -7.6073e-23, -9.5198e-29,  8.0978e-34,\n",
      "        -1.6924e-40, -1.4666e-19,  2.8923e-03, -2.0388e-23,  3.3322e-26,\n",
      "        -2.6825e-31,  1.7135e-17, -2.1404e-26,  1.6212e-02, -8.6206e-20,\n",
      "        -2.4727e-21,  3.2037e-22, -6.8278e-19, -2.6438e-29,  1.4503e-42,\n",
      "         4.0270e-21, -7.4725e-16, -8.8199e-05, -4.5641e-19, -5.8884e-30,\n",
      "        -8.2826e-17, -5.7929e-33, -1.9166e-27,  4.3546e-28,  2.9348e-24,\n",
      "        -1.1197e-36, -1.8071e-37,  3.5622e-02, -6.3015e-21, -1.7146e-23,\n",
      "        -1.8928e-29,  1.6981e-19,  1.4677e-29,  2.0057e-02, -4.4913e-27,\n",
      "        -7.4902e-25, -1.4475e-39,  6.7812e-03,  1.2632e-28, -1.4981e-28,\n",
      "         2.3160e-20,  1.4372e-26], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 4.7819e-18, -8.8835e-02, -4.2734e-19,  ..., -2.6614e-26,\n",
      "         -4.8852e-17, -1.8544e-22],\n",
      "        [ 4.7833e-18,  8.8834e-02, -4.2742e-19,  ..., -2.6905e-26,\n",
      "         -4.8895e-17, -1.8546e-22]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0499, -0.0499], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d50cad6-35fb-43d5-8120-78f43f7c3693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.1 in /isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages (from scikit-image) (1.24.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages (from scikit-image) (1.11.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages (from scikit-image) (10.0.0)\n",
      "Collecting imageio>=2.27 (from scikit-image)\n",
      "  Downloading imageio-2.31.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2023.8.25-py3-none-any.whl (221 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21 in /isilon/datalake/lcbn_research/final/software/LCBN/miniconda3/envs/gnn/lib/python3.10/site-packages (from scikit-image) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image)\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 imageio-2.31.2 lazy_loader-0.3 scikit-image-0.21.0 tifffile-2023.8.25\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71200676-edc7-498d-87b2-f02dac825a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from skimage.io import imread, savemat\n",
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc4bcf05-208c-447d-a810-a194bb0aa69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias\n",
      "nn.0.weight\n",
      "nn.2.weight\n",
      "nn.2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha1': array([[-2.325455e-41,  1.173447e-41,  3.289969e-41,  3.352186e-41,\n",
       "         -4.223654e-41,  3.910043e-41, -1.895957e-41, -2.540554e-42,\n",
       "          2.005398e-41, -1.152568e-41, -1.611493e-43, -3.708116e-41,\n",
       "         -4.809396e-41, -1.275041e-41, -1.367247e-41, -1.474166e-41,\n",
       "         -1.607990e-41, -4.560946e-41, -6.892987e-42, -5.452733e-41,\n",
       "          4.151347e-41,  9.122453e-42,  8.036447e-42, -1.014400e-41,\n",
       "          3.288007e-41,  3.142692e-41, -3.490494e-41, -4.002249e-41,\n",
       "          3.621376e-41, -3.452099e-41],\n",
       "        [-2.689092e-42,  1.668386e-41, -1.524052e-41, -2.798393e-42,\n",
       "          8.929214e-41, -9.409719e-42, -1.854619e-40, -5.440401e-41,\n",
       "         -2.971313e-41,  6.513235e-42,  1.501393e-40,  8.962285e-41,\n",
       "         -3.811532e-41,  1.774184e-41,  1.036260e-40, -4.529137e-41,\n",
       "         -3.651363e-41, -5.071159e-41, -1.180314e-41, -6.182529e-42,\n",
       "          3.319345e-39,  6.915237e-39,  1.428512e-40, -9.665736e-41,\n",
       "         -4.008695e-41,  8.934609e-40,  1.007833e-39,  4.155971e-41,\n",
       "          2.569057e-40,  2.264737e-40],\n",
       "        [-1.216299e-40,  3.032270e-41,  5.743922e-42, -1.081242e-41,\n",
       "         -4.294700e-41, -2.125770e-41, -9.212837e-41, -2.207045e-41,\n",
       "          1.081662e-41, -1.782312e-41, -2.065794e-41, -1.204416e-41,\n",
       "         -2.572223e-41, -2.122687e-41, -2.778074e-41, -2.089336e-41,\n",
       "         -4.298483e-41,  1.397515e-41, -4.996049e-41, -4.528997e-42,\n",
       "         -3.026104e-41, -8.596966e-42,  5.104510e-41,  2.442743e-41,\n",
       "          2.149312e-41, -3.461067e-41, -3.059035e-42, -3.275255e-41,\n",
       "         -3.408378e-41, -3.436825e-41]], dtype=float32),\n",
       " 'beta1': array([[ 6.8495e-42,  1.0095e-41,  2.4228e-41],\n",
       "        [-3.9128e-41, -8.7343e-42, -2.1382e-41],\n",
       "        [ 3.8623e-41,  1.6224e-41,  1.0291e-41],\n",
       "        ...,\n",
       "        [-4.6993e-41,  3.9606e-41, -2.5223e-42],\n",
       "        [ 1.2288e-41, -3.2380e-41, -2.5729e-41],\n",
       "        [-2.0578e-41,  1.6597e-41, -3.6348e-41]], dtype=float32),\n",
       " 'alpha2': array([[-1.90338e-41, -2.55775e-40, -6.23578e-42, -1.11768e-41,\n",
       "          1.25856e-40,  1.16269e-40, -1.48173e-41, -1.33235e-41,\n",
       "          5.96393e-42, -1.45203e-41, -1.07746e-41, -2.43420e-41,\n",
       "         -4.95219e-42, -9.66756e-42, -5.75934e-43, -1.39822e-41,\n",
       "         -2.11610e-41, -2.75958e-41, -2.16360e-41, -2.61604e-40,\n",
       "         -1.56385e-41,  9.99224e-41, -9.92119e-43, -7.02471e-42,\n",
       "          1.68856e-42, -1.15705e-41,  1.15887e-41,  8.07148e-42,\n",
       "          2.11638e-41, -1.64891e-41],\n",
       "        [ 1.45763e-41, -7.12280e-42, -5.62902e-42,  2.36063e-41,\n",
       "          2.66577e-40, -9.01315e-42,  6.41094e-42,  3.93765e-42,\n",
       "          1.57390e-40,  1.61177e-41,  2.08625e-41,  9.05939e-42,\n",
       "         -6.79910e-42,  1.89820e-41,  4.16886e-42,  3.69943e-42,\n",
       "         -2.83553e-41, -1.45707e-41, -7.99020e-42,  1.28723e-41,\n",
       "          1.09091e-41, -1.66208e-41,  4.45473e-42, -7.02891e-42,\n",
       "         -1.69501e-41,  6.11667e-42, -4.40568e-42, -1.29186e-41,\n",
       "          3.09687e-43,  8.26906e-42],\n",
       "        [-1.88075e-40, -5.44545e-42,  2.64005e-42,  2.02151e-41,\n",
       "          9.73482e-42, -2.66247e-41, -2.31144e-41,  9.27940e-42,\n",
       "         -4.09880e-42,  8.77913e-42,  8.74410e-43, -8.59837e-42,\n",
       "         -8.16957e-42,  1.14122e-41,  9.00755e-42, -1.43227e-41,\n",
       "         -1.07648e-41, -1.60869e-42,  8.09530e-41,  1.16182e-41,\n",
       "          1.15530e-40, -2.27487e-41, -8.09951e-42,  1.02642e-40,\n",
       "         -1.85798e-41,  3.94886e-42,  1.24085e-41, -5.73692e-42,\n",
       "          1.26187e-41,  1.95551e-41]], dtype=float32),\n",
       " 'beta2': array([[-1.3335e-41,  2.0766e-41,  1.9062e-41],\n",
       "        [-1.5203e-41, -1.2711e-41,  6.8986e-42],\n",
       "        [-5.4281e-41,  7.9846e-42, -2.3271e-41],\n",
       "        ...,\n",
       "        [ 2.3856e-41,  1.3607e-41, -1.6834e-41],\n",
       "        [ 1.4531e-42, -1.3380e-41, -1.2707e-41],\n",
       "        [ 1.4321e-42,  2.3651e-41, -4.2768e-42]], dtype=float32)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for name, t in model.conv1.state_dict().items():\n",
    "    print(name)\n",
    "    arr = t.numpy()\n",
    "    if name == \"nn.0.weight\":\n",
    "        #savemat(\"conv1alpha.tif\",arr)\n",
    "        d[\"alpha1\"] = arr.copy()\n",
    "    if name == \"nn.2.weight\":\n",
    "        #savemat(arr, \"conv1beta.tif\",arr)\n",
    "        d[\"beta1\"]=arr.copy()\n",
    "for name, t in model.conv2.state_dict().items():\n",
    "    arr = t.numpy()\n",
    "    if name == \"nn.0.weight\":\n",
    "        #savemat(arr, \"conv2alpha.tif\",arr)\n",
    "        d[\"alpha2\"] = arr.copy()\n",
    "    if name == \"nn.2.weight\":\n",
    "        #savemat(arr, \"conv2beta.tif\",arr)\n",
    "        d[\"beta2\"] = arr.copy()\n",
    "savemat(\"simulation_weights.mat\", d)\n",
    "d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "024bdf47-fa24-4c8d-86e0-467c60371029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07140078  0.05467945 -0.7055184 ]\n",
      " [-0.95947665 -0.02671944 -0.02042726]\n",
      " [-0.023392   -0.02111588  0.00990349]\n",
      " [-0.04192687  0.08855317  0.07583212]\n",
      " [ 0.47211885  1.          0.0365178 ]\n",
      " [ 0.436153   -0.03381063 -0.09987594]\n",
      " [-0.05558359  0.02404908 -0.08670809]\n",
      " [-0.04998003  0.01477113  0.0348094 ]\n",
      " [ 0.02237221  0.59040874 -0.01537564]\n",
      " [-0.05446919  0.06046174  0.03293278]\n",
      " [-0.04041822  0.07826069  0.00328014]\n",
      " [-0.09131289  0.0339841  -0.03225467]\n",
      " [-0.01857693 -0.02550516 -0.03064615]\n",
      " [-0.03626548  0.07120629  0.04280998]\n",
      " [-0.00216047  0.01563847  0.03378961]\n",
      " [-0.05245064  0.0138775  -0.053728  ]\n",
      " [-0.07938035 -0.10636788 -0.04038142]\n",
      " [-0.10351878 -0.05465842 -0.00603461]\n",
      " [-0.08116235 -0.0299733   0.30367544]\n",
      " [-0.9813442   0.04828739  0.04358271]\n",
      " [-0.05866398  0.04092285  0.43338275]\n",
      " [ 0.37483442 -0.06234887 -0.08533611]\n",
      " [-0.00372169  0.01671082 -0.03038331]\n",
      " [-0.02635148 -0.02636725  0.38503754]\n",
      " [ 0.00633424 -0.06358418 -0.06969764]\n",
      " [-0.04340398  0.02294518  0.01481318]\n",
      " [ 0.04347232 -0.01652684  0.04654745]\n",
      " [ 0.03027818 -0.04846086 -0.02152064]\n",
      " [ 0.07939086  0.00116171  0.04733594]\n",
      " [-0.06185475  0.03101937  0.07335626]]\n",
      "[1 2 2 1 1 0 1 2 1 1 1 1 0 1 2 1 2 2 2 1 2 0 1 2 0 1 2 0 0 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, t in model.conv2.state_dict().items():\n",
    "    if name == \"nn.0.weight\":\n",
    "        arr = t.numpy()\n",
    "        #print(arr)\n",
    "        arr = arr/arr.max()\n",
    "        print(arr.T)\n",
    "        print(np.argmax((arr.T), axis =1))\n",
    "        plt.imshow(arr, cmap = \"OrRd\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad24b9-90e9-4db4-aee2-c381d1f486ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
